{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import ascii_letters, digits\n",
    "import utils.cleaning_dicts\n",
    "#import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_w7.csv\t\t\t       other_data\r\n",
      "chromedriver\t\t\t       pfr\r\n",
      "covers_scrape.py\t\t       pfr_injuries.py\r\n",
      "create_modeling_data_2022.ipynb        rbbio.csv\r\n",
      "create_modeling_data_sample_all.ipynb  README.md\r\n",
      "create_player_pools_2022.ipynb\t       rushroll.csv\r\n",
      "current_data\t\t\t       scripts\r\n",
      "fo_addtohist_update.csv\t\t       spreads_data\r\n",
      "historic_data\t\t\t       sumconcrollrb.csv\r\n",
      "injhist.csv\t\t\t       update_spreads_file.py\r\n",
      "misc_files\t\t\t       utils\r\n",
      "modeling_data\t\t\t       weather_scraper_current_year.py\r\n",
      "notebooks\r\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.path.abspath(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Users must change the week values to the current week in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_week_int = 9\n",
    "cur_week_str = str(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in, clean and process all pff position datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "                ###   Read-in and clean all passing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "passing_depth = pd.read_csv('./historic_data/pff_data/passing_depth_hist.csv')\n",
    "passing_allowed_pressure = pd.read_csv('./historic_data/pff_data/passing_allowed_pressure_hist.csv')\n",
    "passing_pressure = pd.read_csv('./historic_data/pff_data/passing_pressure_hist.csv')\n",
    "passing_concept = pd.read_csv('./historic_data/pff_data/passing_concept_hist.csv')\n",
    "time_in_pocket = pd.read_csv('./historic_data/pff_data/time_in_pocket_hist.csv')\n",
    "passing_summ_conc = pd.read_csv('./historic_data/pff_data/passing_summ_conc_hist.csv')\n",
    "\n",
    "passing_depth_new = pd.read_csv('./scripts/nfl_all/passing_depth_2022.csv')\n",
    "passing_allowed_pressure_new = pd.read_csv('./scripts/nfl_all/passing_allowed_pressure_2022.csv')\n",
    "passing_pressure_new = pd.read_csv('./scripts/nfl_all/passing_pressure_2022.csv')\n",
    "passing_concept_new = pd.read_csv('./scripts/nfl_all/passing_concept_2022.csv')\n",
    "time_in_pocket_new = pd.read_csv('./scripts/nfl_all/time_in_pocket_2022.csv')\n",
    "passing_summ_conc_new = pd.read_csv('./scripts/nfl_all/passing_summ_conc_2022.csv')\n",
    "                                 \n",
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0).reset_index(drop=True)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0).reset_index(drop=True)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0).reset_index(drop=True)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "\n",
    "def drop_non_qbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df=df[df['position'] == 'QB']\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "    \n",
    "passing_depth = drop_non_qbs(passing_depth)\n",
    "passing_allowed_pressure = drop_non_qbs(passing_allowed_pressure)\n",
    "passing_pressure = drop_non_qbs(passing_pressure)\n",
    "passing_concept = drop_non_qbs(passing_concept)\n",
    "time_in_pocket = drop_non_qbs(time_in_pocket)\n",
    "passing_summ_conc = drop_non_qbs(passing_summ_conc)\n",
    "\n",
    "\n",
    "passing_depth = passing_depth[passing_depth.columns.drop(list(passing_depth.filter(regex='left|right|center')))]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all receiving datasets ### scripts/nfl_all\n",
    "####################################################################################\n",
    "\n",
    "rec_summ_conc = pd.read_csv('./historic_data/pff_data/rec_summ_conc_hist.csv')\n",
    "receiving_concept = pd.read_csv('./historic_data/pff_data/receiving_concept_hist.csv')\n",
    "receiving_depth = pd.read_csv('./historic_data/pff_data/receiving_depth_hist.csv')\n",
    "receiving_scheme = pd.read_csv('./historic_data/pff_data/receiving_scheme_hist.csv')\n",
    "                                 \n",
    "rec_summ_conc_new = pd.read_csv('./scripts/nfl_all/rec_summ_conc_2022.csv')\n",
    "receiving_concept_new = pd.read_csv('./scripts/nfl_all/receiving_concept_2022.csv')\n",
    "receiving_depth_new = pd.read_csv('./scripts/nfl_all/receiving_depth_2022.csv')\n",
    "receiving_scheme_new = pd.read_csv('./scripts/nfl_all/receiving_scheme_2022.csv')\n",
    "                                 \n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0).reset_index(drop=True)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0).reset_index(drop=True)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0).reset_index(drop=True)                                 \n",
    "\n",
    "def drop_non_recs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|TE|HB|FB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rec_summ_conc = drop_non_recs(rec_summ_conc)\n",
    "receiving_concept = drop_non_recs(receiving_concept)\n",
    "receiving_depth = drop_non_recs(receiving_depth)\n",
    "receiving_scheme = drop_non_recs(receiving_scheme)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all rushing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "rush_summ_conc = pd.read_csv('./historic_data/pff_data/rush_summ_conc_hist.csv')\n",
    "rush_summ_conc_new = pd.read_csv('./scripts/nfl_all/rush_summ_conc_2022.csv')                                 \n",
    "                                 \n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    " \n",
    "\n",
    "def drop_non_rbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|HB|FB|QB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rush_summ_conc = drop_non_rbs(rush_summ_conc)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all blocking datasets ###\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "block_summ_conc = pd.read_csv('./historic_data/pff_data/block_summ_conc_hist.csv')\n",
    "offense_pass_blocking = pd.read_csv('./historic_data/pff_data/offense_pass_blocking_hist.csv')\n",
    "offense_run_blocking = pd.read_csv('./historic_data/pff_data/offense_run_blocking_hist.csv')\n",
    "                                 \n",
    "block_summ_conc_new = pd.read_csv('./scripts/nfl_all/block_summ_conc_2022.csv')\n",
    "offense_pass_blocking_new = pd.read_csv('./scripts/nfl_all/offense_pass_blocking_2022.csv')\n",
    "offense_run_blocking_new = pd.read_csv('./scripts/nfl_all/offense_run_blocking_2022.csv')                                 \n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0).reset_index(drop=True)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "def drop_non_ols(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df = df[df['position'].notna()]\n",
    "    df= df[df.position.str.match('T|C|G|TE')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "\n",
    "block_summ_conc\t= drop_non_ols(block_summ_conc)\n",
    "offense_pass_blocking = drop_non_ols(offense_pass_blocking)\n",
    "offense_run_blocking = drop_non_ols(offense_run_blocking)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all defensive datasets ###\n",
    "####################################################################################\n",
    "\n",
    "def_summ_conc = pd.read_csv('./historic_data/pff_data/def_summ_conc_hist.csv')\n",
    "pass_rush_summary = pd.read_csv('./historic_data/pff_data/pass_rush_summary_hist.csv')\n",
    "run_defense_summary = pd.read_csv('./historic_data/pff_data/run_defense_summary_hist.csv')\n",
    "defense_coverage_scheme = pd.read_csv('./historic_data/pff_data/defense_coverage_scheme_hist.csv')\n",
    "defense_coverage_summary = pd.read_csv('./historic_data/pff_data/defense_coverage_summary_hist.csv')\n",
    "slot_coverage = pd.read_csv('./historic_data/pff_data/slot_coverage_hist.csv')\n",
    "                                 \n",
    "def_summ_conc_new = pd.read_csv('./scripts/nfl_all/def_summ_conc_2022.csv')\n",
    "pass_rush_summary_new = pd.read_csv('./scripts/nfl_all/pass_rush_summary_2022.csv')\n",
    "run_defense_summary_new = pd.read_csv('./scripts/nfl_all/run_defense_summary_2022.csv')\n",
    "defense_coverage_scheme_new = pd.read_csv('./scripts/nfl_all/defense_coverage_scheme_2022.csv')\n",
    "defense_coverage_summary_new = pd.read_csv('./scripts/nfl_all/defense_coverage_summary_2022.csv')\n",
    "slot_coverage_new = pd.read_csv('./scripts/nfl_all/slot_coverage_2022.csv')\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0).reset_index(drop=True)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0).reset_index(drop=True)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def drop_non_def(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "def_summ_conc = drop_non_def(def_summ_conc)\n",
    "pass_rush_summary = drop_non_def(pass_rush_summary)\n",
    "run_defense_summary = drop_non_def(run_defense_summary)\n",
    "defense_coverage_scheme = drop_non_def(defense_coverage_scheme)\n",
    "defense_coverage_summary = drop_non_def(defense_coverage_summary)\n",
    "slot_coverage = drop_non_def(slot_coverage)\n",
    "\n",
    "def_summ_conc=def_summ_conc[def_summ_conc['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "pass_rush_summary=pass_rush_summary[pass_rush_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\"])]\n",
    "run_defense_summary=run_defense_summary[run_defense_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "defense_coverage_scheme=defense_coverage_scheme[defense_coverage_scheme['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "defense_coverage_summary=defense_coverage_summary[defense_coverage_summary['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "slot_coverage=slot_coverage[slot_coverage['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all special teams datasets ###\n",
    "####################################################################################\t\n",
    "\n",
    "st_kickers = pd.read_csv('./historic_data/pff_data/st_kickers_hist.csv')\n",
    "st_punters = pd.read_csv('./historic_data/pff_data/st_punters_hist.csv')\n",
    "\n",
    "st_kickers_new = pd.read_csv('./scripts/nfl_all/st_kickers_2022.csv')\n",
    "st_punters_new = pd.read_csv('./scripts/nfl_all/st_punters_2022.csv')                                 \n",
    "                                 \n",
    "                                 \n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0).reset_index(drop=True)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def clean_spec(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "st_kickers =clean_spec(st_kickers)\n",
    "st_punters = clean_spec(st_punters)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute all missing values in pff dataframe - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 219 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth = impute(passing_depth)\n",
    "passing_allowed_pressure = impute(passing_allowed_pressure)\n",
    "passing_pressure = impute(passing_pressure)\n",
    "passing_concept = impute(passing_concept)\n",
    "time_in_pocket = impute(time_in_pocket)\n",
    "passing_summ_conc = impute(passing_summ_conc)\n",
    "\n",
    "rec_summ_conc = impute(rec_summ_conc)\n",
    "receiving_concept = impute(receiving_concept)\n",
    "receiving_depth = impute(receiving_depth)\n",
    "receiving_scheme = impute(receiving_scheme)\n",
    "\n",
    "rush_summ_conc = impute(rush_summ_conc)\n",
    "\n",
    "block_summ_conc = impute(block_summ_conc)\n",
    "offense_pass_blocking = impute(offense_pass_blocking)\n",
    "offense_run_blocking = impute(offense_run_blocking)\n",
    "\n",
    "def_summ_conc = impute(def_summ_conc)\n",
    "pass_rush_summary = impute(pass_rush_summary)\n",
    "run_defense_summary = impute(run_defense_summary)\n",
    "defense_coverage_scheme = impute(defense_coverage_scheme)\n",
    "defense_coverage_summary = impute(defense_coverage_summary)\n",
    "slot_coverage = impute(slot_coverage)\n",
    "\n",
    "st_kickers = impute(st_kickers)\n",
    "st_punters = impute(st_punters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prefixes to all columns.  Creating column names structured as \"source-dataset_column-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc)\n",
    "rush_summ_conc = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc)\n",
    "rec_summ_conc = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc)\n",
    "block_summ_conc = id_prefix(prefix=\"block_summary_\", df=block_summ_conc)\n",
    "def_summ_conc = id_prefix(prefix=\"def_summary_\", df=def_summ_conc)\n",
    "st_kickers = id_prefix(prefix=\"kicking_\", df=st_kickers)\n",
    "st_punters = id_prefix(prefix=\"punting_\", df=st_punters)\n",
    "\n",
    "\n",
    "passing_depth = create_prefix(prefix=\"pass_depth_\", df=passing_depth)\n",
    "passing_allowed_pressure = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure)\n",
    "passing_pressure = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure)\n",
    "passing_concept = create_prefix(prefix=\"pass_concept_\", df=passing_concept)\n",
    "time_in_pocket = create_prefix(prefix=\"pass_time_\", df=time_in_pocket)\n",
    "\n",
    "\n",
    "receiving_concept = create_prefix(prefix=\"rec_concept_\", df=receiving_concept)\n",
    "receiving_depth = create_prefix(prefix=\"rec_depth_\", df=receiving_depth)\n",
    "receiving_scheme = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme)\n",
    "\n",
    "offense_pass_blocking = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking)\n",
    "offense_run_blocking = create_prefix(prefix=\"run_block_\", df=offense_run_blocking)\n",
    "\n",
    "\n",
    "pass_rush_summary = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary)\n",
    "run_defense_summary = create_prefix(prefix=\"run_defense_\", df=run_defense_summary)\n",
    "defense_coverage_scheme = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme)\n",
    "defense_coverage_summary = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary)\n",
    "slot_coverage = create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in weather data and clean raiders name - merged onto spreads data below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in weather data###\n",
    "weather = pd.read_csv('./current_data/week_'+cur_week_str+'/weather_hist_all.csv')\n",
    "\n",
    "def raiders(df):\n",
    "    if 'oak' in str(df.away_matchup_id) and '2020' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2021' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2022' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    else:\n",
    "        return df.away_matchup_id\n",
    "weather['away_matchup_id'] = weather.apply(lambda df: raiders(df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spreads data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t###   spreads data cleaning and engineering ###\n",
    "####################################################################################\n",
    "\n",
    "spreads = pd.read_csv('./current_data/week_'+cur_week_str+'/spreadsw'+cur_week_str+'.csv')\n",
    "\n",
    "new_acc = {'oak':'lv',\n",
    "          'sd':'lac',\n",
    "          'stl':'lar'}  \n",
    "\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].map(new_acc).fillna(spreads['team_home_abb'])\n",
    "spreads['away_team_abb'] = spreads['away_team_abb'].map(new_acc).fillna(spreads['away_team_abb']) \n",
    "\n",
    "spreads = spreads[spreads['schedule_season']>=2014]\n",
    "spreads = spreads[['schedule_season','schedule_week','team_home_abb','score_home','score_away','away_team_abb','team_favorite_id','spread_favorite','over_under_line','starting_spread', 'Total Score Open',\n",
    "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement','ou_movement', 'strong_movement', 'fav_team_stronger']]\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].astype(str)\n",
    "spreads['team_favorite_id'] = spreads['team_favorite_id'].astype(str)\n",
    "spreads['over_under_line'] = spreads['over_under_line'].astype(float)\n",
    "\n",
    "\n",
    "def fav_spread(nData):\n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    else:\n",
    "        pass\n",
    "spreads['fav_spread'] = spreads.apply(lambda nData: fav_spread(nData), axis=1)\n",
    "\n",
    "def nonfav_spread(nData):\n",
    "    if nData['team_home_abb'] != nData['team_favorite_id']:\n",
    "        return nData['team_home_abb']\n",
    "    elif nData['away_team_abb'] != nData['team_favorite_id']:\n",
    "        return nData['away_team_abb']\n",
    "    else:\n",
    "        pass\n",
    "spreads['team_notfav_id'] = spreads.apply(lambda nData: nonfav_spread(nData), axis=1)\n",
    "\n",
    "def cover_or_not(nData):    \n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        if ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] > 0:\n",
    "            return 'Cover'\n",
    "        elif ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'       \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:        \n",
    "        if ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] > 0:            \n",
    "            return 'Cover'        \n",
    "        elif ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'        \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "spreads['fav_cover'] = spreads.apply(lambda nData: cover_or_not(nData), axis=1)\n",
    "\n",
    "def OU_or_not(nData):    \n",
    "    if (nData['score_home']+nData['score_away']) > nData['over_under_line']:        \n",
    "        return 'Over'    \n",
    "    elif (nData['score_home']-nData['score_away']) == nData['over_under_line']:        \n",
    "        return 'Push'    \n",
    "    else:        \n",
    "        return 'Under'\n",
    "spreads['over_under_result'] = spreads.apply(lambda nData: OU_or_not(nData), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "spreads['schedule_season'] = spreads['schedule_season'].apply(int)    \n",
    "spreads['schedule_week'] = spreads['schedule_week'].apply(int)  \n",
    "data = spreads.sort_values(by=[\"team_home_abb\",\"schedule_season\",\"schedule_week\"], ascending=[True, True, True])\n",
    "\n",
    "def clean_spreads(df):\n",
    "    ##  basic scrubbing to clean data ##    \n",
    "    df['schedule_season'] = df['schedule_season'].apply(str)    \n",
    "    df['schedule_week'] = df['schedule_week'].apply(str)        \n",
    "    df=df.apply(lambda x: x.astype(str).str.lower())    \n",
    "    #df['schedule_week']=df['schedule_week'].astype(str).str[:-2].astype(object)    \n",
    "    #df['schedule_season'] = df['schedule_season'].astype(str).str[:-2].astype(object)  \n",
    "    df['team_home_abb'] = df['team_home_abb'].map(new_acc).fillna(df['team_home_abb'])\n",
    "    df['away_team_abb'] = df['away_team_abb'].map(new_acc).fillna(df['away_team_abb'])\n",
    "    \n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"home_matchup_id\", (df['team_home_abb']+'vs'+df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(1, \"away_matchup_id\", (df['away_team_abb']+'@'+df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(2, \"home_id\", (df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(3, \"away_id\", (df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    return df\n",
    "    \n",
    "data = clean_spreads(data)\n",
    "\n",
    "data = pd.merge(data, weather, on='away_matchup_id', how='left')\n",
    "\n",
    "\n",
    "sh = data\n",
    "sa = data\n",
    "\n",
    "sh = sh.rename(columns={'home_id':'team_id'})\n",
    "sh.drop('away_id', axis=1, inplace=True)\n",
    "\n",
    "sa = sa.rename(columns={'away_id':'team_id'})\n",
    "sa.drop('home_id', axis=1, inplace=True)\n",
    "\n",
    "spread_comb = pd.concat([sh, sa], axis=0)\n",
    "spread_comb['team_abb'] = spread_comb['team_id'].astype(str).str[:3]\n",
    "spread_comb['team_abb'] = spread_comb['team_abb'].str.replace(\"_\",\"\")\n",
    "\n",
    "def hora1(nData):\n",
    "    if nData['team_favorite_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    elif nData['team_notfav_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['homeoraway'] = spread_comb.apply(lambda nData: hora1(nData), axis=1)\n",
    "\n",
    "def hora(nData):\n",
    "    if nData['team_favorite_id'] == nData['away_team_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['fav_homeoraway'] = spread_comb.apply(lambda nData: hora(nData), axis=1)\n",
    "#sh['fav_homeoraway'] = sh.apply(lambda nData: hora(nData), axis=1)\n",
    "\n",
    "def ws(nData):\n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ls(nData):    \n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "spread_comb['ats_w'] = spread_comb.apply(lambda nData: ws(nData), axis=1)\n",
    "spread_comb['ats_l'] = spread_comb.apply(lambda nData: ls(nData), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_matchup_id', 'away_matchup_id', 'team_id', 'schedule_season',\n",
       "       'schedule_week', 'team_home_abb', 'score_home', 'score_away',\n",
       "       'away_team_abb', 'team_favorite_id', 'spread_favorite',\n",
       "       'over_under_line', 'starting_spread', 'Total Score Open',\n",
       "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement',\n",
       "       'ou_movement', 'strong_movement', 'fav_team_stronger', 'fav_spread',\n",
       "       'team_notfav_id', 'fav_cover', 'over_under_result', 'precip', 'dome',\n",
       "       'temperature', 'wind_mph', 'team_abb', 'homeoraway', 'fav_homeoraway',\n",
       "       'ats_w', 'ats_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread_comb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Football Outsiders rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rolling_fo(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    #data=data.fillna(data.mean())\n",
    "    num_cols = ['total_dvoa', 'off_dvoa','off_pass_dvoa', 'off_rush_dvoa', 'def_dvoa', 'def_pass_dvoa','def_rush_dvoa', 'special_teams_dvoa']\n",
    "    ids = data[['team_id', 'year', 'team', 'week', 'opp']].reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in historic weekly football outsiders data and create the current week rows for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>63</th>\n",
       "      <th>575</th>\n",
       "      <th>1103</th>\n",
       "      <th>1615</th>\n",
       "      <th>2127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_id</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2015_1</td>\n",
       "      <td>ari_2016_1</td>\n",
       "      <td>ari_2017_1</td>\n",
       "      <td>ari_2018_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "      <td>2017</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          63          575         1103        1615        2127\n",
       "team_id             ari_2014_1  ari_2015_1  ari_2016_1  ari_2017_1  ari_2018_1\n",
       "year                      2014        2015        2016        2017        2018\n",
       "team                       ari         ari         ari         ari         ari\n",
       "week                         9           9           9           9           9\n",
       "opp                        NaN         NaN         NaN         NaN         NaN\n",
       "total_dvoa                 NaN         NaN         NaN         NaN         NaN\n",
       "off_dvoa                   NaN         NaN         NaN         NaN         NaN\n",
       "off_pass_dvoa              NaN         NaN         NaN         NaN         NaN\n",
       "off_rush_dvoa              NaN         NaN         NaN         NaN         NaN\n",
       "def_dvoa                   NaN         NaN         NaN         NaN         NaN\n",
       "def_pass_dvoa              NaN         NaN         NaN         NaN         NaN\n",
       "def_rush_dvoa              NaN         NaN         NaN         NaN         NaN\n",
       "special_teams_dvoa         NaN         NaN         NaN         NaN         NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t##Create the current weeks fo team_ids/rows to roll into##\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "fo_data_new = fo_data[~fo_data['week'].isnull()]\n",
    "fo_data_new=fo_data_new.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "fo_data_new['team_id'] = fo_data_new['team_id'].str[:-1]\n",
    "fo_data_new['team_id']=fo_data_new['team_id'].str.replace(\"2022_\", str(\"2022_\"+cur_week_str))\n",
    "\n",
    "\n",
    "fo_data_new = fo_data_new.sort_values(by=[\"team\",\"week\"], ascending=[True, False])\n",
    "fo_data_new[fo_data_new.columns[4:]] = np.nan\n",
    "fo_data_new.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in the historic FO data and concat all of them together for our rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_team_id</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2014_2</td>\n",
       "      <td>ari_2014_2</td>\n",
       "      <td>ari_2014_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.496667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.423333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>29.8</td>\n",
       "      <td>24.366667</td>\n",
       "      <td>18.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>44.733333</td>\n",
       "      <td>38.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1           2           3           4\n",
       "unique_team_id      ari_2014_1  ari_2014_1  ari_2014_2  ari_2014_2  ari_2014_3\n",
       "total_dvoa                 NaN        0.59        0.59    0.613333    0.636667\n",
       "off_dvoa                   NaN        0.53        0.53    0.513333    0.496667\n",
       "off_pass_dvoa              NaN        0.53        0.53    0.476667    0.423333\n",
       "off_rush_dvoa              NaN        0.51        0.51        0.55        0.59\n",
       "def_dvoa                   NaN        29.8        29.8   24.366667   18.933333\n",
       "def_pass_dvoa              NaN        14.2        14.2        10.1         6.0\n",
       "def_rush_dvoa              NaN        51.3        51.3   44.733333   38.166667\n",
       "special_teams_dvoa         NaN        0.35        0.35    0.523333    0.696667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo_data_2022 = pd.read_csv(\"./historic_data/fo_data/fo_weekly_hist.csv\")\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "\n",
    "fo = pd.concat([fo_data_2022, fo_data, fo_data_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "fo['team'] = fo['team'].map(new_acc).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(new_acc).fillna(fo['opp']) \n",
    "\n",
    "fo['team'] = fo['team'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['opp'])\n",
    "\n",
    "##combine our current season fo data with the new week 4 rows we just made##\n",
    "fo_roll = rolling_fo(data=fo, roll_value=3, roll_type='mean')\n",
    "fo_roll = fo_roll.rename(columns={'team_id': 'unique_team_id'})\n",
    "\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('sd_','lac_')\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('oak_','lv_')\n",
    "fo_roll.drop(['year','team','week','opp'], axis=1, inplace=True)\n",
    "\n",
    "fo_roll.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFF team_game_summaries (tgs) clean and create current week rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_new_week = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "\n",
    "tgs_new_week = tgs_new_week[~tgs_new_week['week'].isnull()]\n",
    "tgs_new_week=tgs_new_week.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "\n",
    "tgs_new_week['team_name'] = tgs_new_week['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs_new_week['team'])\n",
    "tgs_new_week['opponent_name'] = tgs_new_week['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs_new_week['opponent'])\n",
    "\n",
    "tgs_new_week['home_or_away']=tgs_new_week['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs_new_week['home_team'] = tgs_new_week.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs_new_week['away_team'] = tgs_new_week.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "tgs_new_week = clean_pff_team_summ(tgs_new_week)\n",
    "tgs_new_week['wl_int'] = ''\n",
    "tgs_new_week = tgs_new_week.sort_values(by=[\"team_name\",\"week\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in historic tgs data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_data_2022 = pd.read_csv(\"./historic_data/pff_data/team_game_summaries_historic.csv\")\n",
    "tgs_data_cur = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "tgs = pd.concat([tgs_data_2022, tgs_data_cur], axis=0)\n",
    "\n",
    "tgs = tgs[tgs['year'] >= 2014]\n",
    "\n",
    "\n",
    "tgs['team_name'] = tgs['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs['team'])\n",
    "tgs['opponent_name'] = tgs['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs['opponent'])\n",
    "\n",
    "##adding just incase accronyms have changed\n",
    "tgs['team_name'] = tgs['team_name'].map(new_acc).fillna(tgs['team_name'])\n",
    "tgs['opponent_name'] = tgs['opponent_name'].map(new_acc).fillna(tgs['opponent_name']) \n",
    "\n",
    "tgs['home_or_away']=tgs['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs['home_team'] = tgs.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs['away_team'] = tgs.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    ##Impute missing special teams data added after 2014##\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_name'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "   \n",
    "    return df\n",
    "\n",
    "\n",
    "   \n",
    "tgs_clean = clean_pff_team_summ(tgs)\n",
    "\n",
    "\n",
    "tgs_clean = pd.concat([tgs_clean, tgs_new_week], axis=0).reset_index(drop=True)\n",
    "tgs_clean['year']=tgs_clean['year'].apply(int)\n",
    "tgs_clean['week']=tgs_clean['week'].apply(int)\n",
    "tgs_clean['special_teams']=tgs_clean['special_teams'].apply(float)\n",
    "tgs_clean = tgs_clean.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "\n",
    "tgs_clean = tgs_clean[['unique_team_id','team_id_impute', 'home_matchup_id','opponent_id','wl','pf','pa','team_name','opponent_name','year','week','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>opponent_id</th>\n",
       "      <th>wl</th>\n",
       "      <th>pf</th>\n",
       "      <th>pa</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>pass_blocking</th>\n",
       "      <th>receiving</th>\n",
       "      <th>rushing</th>\n",
       "      <th>run_blocking</th>\n",
       "      <th>defense</th>\n",
       "      <th>rush_defense</th>\n",
       "      <th>tackling</th>\n",
       "      <th>pass_rush</th>\n",
       "      <th>coverage</th>\n",
       "      <th>special_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>was_2022_5</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsten_2022_5</td>\n",
       "      <td>ten_2022_5</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>ten</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>67.8</td>\n",
       "      <td>61.4</td>\n",
       "      <td>42.9</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>70.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>64.6</td>\n",
       "      <td>43.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>was_2022_6</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>chivswas_2022_6</td>\n",
       "      <td>chi_2022_6</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>was</td>\n",
       "      <td>chi</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>72.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>60.4</td>\n",
       "      <td>72.4</td>\n",
       "      <td>71.9</td>\n",
       "      <td>47.7</td>\n",
       "      <td>39.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>71.9</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>was_2022_7</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsgb_2022_7</td>\n",
       "      <td>gb_2022_7</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>gb</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>65.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>was_2022_8</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>indvswas_2022_8</td>\n",
       "      <td>ind_2022_8</td>\n",
       "      <td>W</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>was</td>\n",
       "      <td>ind</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>71.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>64.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>was_2022_9</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>indvswas_2022_9</td>\n",
       "      <td>ind_2022_9</td>\n",
       "      <td>W</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>was</td>\n",
       "      <td>ind</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>71.1</td>\n",
       "      <td>66.9</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.8</td>\n",
       "      <td>64.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id team_id_impute  home_matchup_id opponent_id wl  pf  pa  \\\n",
       "4370     was_2022_5       was_2022  wasvsten_2022_5  ten_2022_5  L  17  21   \n",
       "4371     was_2022_6       was_2022  chivswas_2022_6  chi_2022_6  W  12   7   \n",
       "4372     was_2022_7       was_2022   wasvsgb_2022_7   gb_2022_7  W  23  21   \n",
       "4373     was_2022_8       was_2022  indvswas_2022_8  ind_2022_8  W  17  16   \n",
       "4405     was_2022_9       was_2022  indvswas_2022_9  ind_2022_9  W  17  16   \n",
       "\n",
       "     team_name opponent_name  year  ...  pass_blocking  receiving  rushing  \\\n",
       "4370       was           ten  2022  ...           52.9       67.8     61.4   \n",
       "4371       was           chi  2022  ...           72.6       49.9     60.4   \n",
       "4372       was            gb  2022  ...           42.1       71.7     65.6   \n",
       "4373       was           ind  2022  ...           61.0       72.9     71.1   \n",
       "4405       was           ind  2022  ...           61.0       72.9     71.1   \n",
       "\n",
       "      run_blocking  defense  rush_defense  tackling  pass_rush  coverage  \\\n",
       "4370          42.9     67.0          64.3      70.7       74.2      64.6   \n",
       "4371          72.4     71.9          47.7      39.6       88.6      71.9   \n",
       "4372          50.0     59.0          71.9      55.0       53.8      59.0   \n",
       "4373          66.9     71.0          71.8      64.2       63.6      67.0   \n",
       "4405          66.9     71.0          71.8      64.2       63.6      67.0   \n",
       "\n",
       "      special_teams  \n",
       "4370           43.9  \n",
       "4371           84.9  \n",
       "4372           66.9  \n",
       "4373           68.0  \n",
       "4405           68.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tgs rolling mean function and combine all tgs datasets together and pass through the rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_tgs(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "        \n",
    "tgs_roll = rolling_tgs(data=tgs_clean, roll_value=3, roll_type='mean')\n",
    "\n",
    "tgs_roll = tgs_roll[['unique_team_id','wl','pf','pa','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_roll = tgs_roll.rename(columns={c: c+'_tgs' for c in tgs_roll.columns if c not in ['unique_team_id','wl','pf','pa']})\n",
    "\n",
    "tgs_roll.rename(columns={'unique_team_id_tgs_pff':'unique_team_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all the pff current week datasets and prep for rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth_new = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/passing_depth_new_pp_w\"+cur_week_str+\".csv\")\n",
    "passing_allowed_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_allowed_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_concept_new_pp_w'+cur_week_str+\".csv\")\n",
    "time_in_pocket_new = pd.read_csv('./current_data/week_'+cur_week_str+'/time_in_pocket_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_summ_conc_new_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "rec_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rec_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_concept_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_depth_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_depth_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "rush_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rush_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "block_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/block_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "offense_pass_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_pass_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "offense_run_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_run_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "def_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/def_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "pass_rush_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/pass_rush_summary_pp_w'+cur_week_str+\".csv\")\n",
    "run_defense_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/run_defense_summary_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_summary_pp_w'+cur_week_str+\".csv\")\n",
    "slot_coverage_new = pd.read_csv('./current_data/week_'+cur_week_str+'/slot_coverage_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "st_kickers_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_kickers_pp_w'+cur_week_str+\".csv\")\n",
    "st_punters_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_punters_no_inj_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "passing_depth_new['week'] = cur_week_str \n",
    "passing_allowed_pressure_new['week'] = cur_week_str \n",
    "passing_pressure_new['week'] = cur_week_str \n",
    "passing_concept_new['week'] = cur_week_str \n",
    "time_in_pocket_new['week'] = cur_week_str \n",
    "passing_summ_conc_new['week'] = cur_week_str \n",
    "rec_summ_conc_new['week'] = cur_week_str \n",
    "receiving_concept_new['week'] = cur_week_str\n",
    "receiving_depth_new['week'] = cur_week_str \n",
    "receiving_scheme_new['week'] = cur_week_str \n",
    "rush_summ_conc_new['week'] = cur_week_str\n",
    "block_summ_conc_new['week'] = cur_week_str \n",
    "offense_pass_blocking_new['week'] = cur_week_str \n",
    "offense_run_blocking_new['week'] = cur_week_str \n",
    "def_summ_conc_new['week'] = cur_week_str \n",
    "pass_rush_summary_new['week'] = cur_week_str \n",
    "run_defense_summary_new['week'] = cur_week_str \n",
    "defense_coverage_scheme_new['week'] = cur_week_str \n",
    "defense_coverage_summary_new['week'] = cur_week_str \n",
    "slot_coverage_new['week'] = cur_week_str \n",
    "st_kickers_new['week'] = cur_week_str \n",
    "st_punters_new['week'] = cur_week_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>player</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>player_game_count</th>\n",
       "      <th>assists</th>\n",
       "      <th>...</th>\n",
       "      <th>tackles</th>\n",
       "      <th>targets</th>\n",
       "      <th>total_pressures</th>\n",
       "      <th>touchdowns</th>\n",
       "      <th>yards</th>\n",
       "      <th>yards_after_catch</th>\n",
       "      <th>yards_per_reception</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>plyr_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>kylehamilton_bal_2022_9</td>\n",
       "      <td>bal_2022_9</td>\n",
       "      <td>kylehamilton_bal_2022</td>\n",
       "      <td>bal_2022</td>\n",
       "      <td>kylehamilton</td>\n",
       "      <td>102684</td>\n",
       "      <td>s</td>\n",
       "      <td>bal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>rodneythomasii_ind_2022_9</td>\n",
       "      <td>ind_2022_9</td>\n",
       "      <td>rodneythomasii_ind_2022</td>\n",
       "      <td>ind_2022</td>\n",
       "      <td>rodneythomasii</td>\n",
       "      <td>108389</td>\n",
       "      <td>s</td>\n",
       "      <td>ind</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>deealford_atl_2022_9</td>\n",
       "      <td>atl_2022_9</td>\n",
       "      <td>deealford_atl_2022</td>\n",
       "      <td>atl_2022</td>\n",
       "      <td>deealford</td>\n",
       "      <td>110542</td>\n",
       "      <td>cb</td>\n",
       "      <td>atl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>domeniquedavis_cin_2022_9</td>\n",
       "      <td>cin_2022_9</td>\n",
       "      <td>domeniquedavis_cin_2022</td>\n",
       "      <td>cin_2022</td>\n",
       "      <td>domeniquedavis</td>\n",
       "      <td>112887</td>\n",
       "      <td>di</td>\n",
       "      <td>cin</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>kaderkohou_mia_2022_9</td>\n",
       "      <td>mia_2022_9</td>\n",
       "      <td>kaderkohou_mia_2022</td>\n",
       "      <td>mia_2022</td>\n",
       "      <td>kaderkohou</td>\n",
       "      <td>156070</td>\n",
       "      <td>cb</td>\n",
       "      <td>mia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p_id unique_team_id           player_team_id  \\\n",
       "653    kylehamilton_bal_2022_9     bal_2022_9    kylehamilton_bal_2022   \n",
       "654  rodneythomasii_ind_2022_9     ind_2022_9  rodneythomasii_ind_2022   \n",
       "655       deealford_atl_2022_9     atl_2022_9       deealford_atl_2022   \n",
       "656  domeniquedavis_cin_2022_9     cin_2022_9  domeniquedavis_cin_2022   \n",
       "657      kaderkohou_mia_2022_9     mia_2022_9      kaderkohou_mia_2022   \n",
       "\n",
       "    team_id_impute          player  numeric_id position team_name  \\\n",
       "653       bal_2022    kylehamilton      102684        s       bal   \n",
       "654       ind_2022  rodneythomasii      108389        s       ind   \n",
       "655       atl_2022       deealford      110542       cb       atl   \n",
       "656       cin_2022  domeniquedavis      112887       di       cin   \n",
       "657       mia_2022      kaderkohou      156070       cb       mia   \n",
       "\n",
       "     player_game_count  assists  ...  tackles  targets  total_pressures  \\\n",
       "653                  1        0  ...        0        0                0   \n",
       "654                  1        0  ...        0        0                0   \n",
       "655                  1        0  ...        0        0                0   \n",
       "656                  1        1  ...        0        0                0   \n",
       "657                  1        0  ...        0        0                0   \n",
       "\n",
       "     touchdowns  yards  yards_after_catch  yards_per_reception  week  year  \\\n",
       "653           0      0                  0                    0     9  2022   \n",
       "654           0      0                  0                    0     9  2022   \n",
       "655           0      0                  0                    0     9  2022   \n",
       "656           0      0                  0                    0     9  2022   \n",
       "657           0      0                  0                    0     9  2022   \n",
       "\n",
       "     plyr_number  \n",
       "653            9  \n",
       "654            9  \n",
       "655            9  \n",
       "656            9  \n",
       "657            9  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the prefixes like we did for the pff datasets above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','team_id_impute','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc_new = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc_new)\n",
    "rush_summ_conc_new  = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc_new)\n",
    "rec_summ_conc_new  = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc_new)\n",
    "block_summ_conc_new  = id_prefix(prefix=\"block_summary_\", df=block_summ_conc_new)\n",
    "def_summ_conc_new  = id_prefix(prefix=\"def_summary_\", df=def_summ_conc_new)\n",
    "st_kickers_new  = id_prefix(prefix=\"kicking_\", df=st_kickers_new)\n",
    "st_punters_new  = id_prefix(prefix=\"punting_\", df=st_punters_new)\n",
    "\n",
    "\n",
    "passing_depth_new = create_prefix(prefix=\"pass_depth_\", df=passing_depth_new)\n",
    "passing_allowed_pressure_new = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure_new)\n",
    "passing_pressure_new = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure_new)\n",
    "passing_concept_new = create_prefix(prefix=\"pass_concept_\", df=passing_concept_new)\n",
    "time_in_pocket_new = create_prefix(prefix=\"pass_time_\", df=time_in_pocket_new)\n",
    "\n",
    "\n",
    "receiving_concept_new = create_prefix(prefix=\"rec_concept_\", df=receiving_concept_new)\n",
    "receiving_depth_new = create_prefix(prefix=\"rec_depth_\", df=receiving_depth_new)\n",
    "receiving_scheme_new = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme_new)\n",
    "\n",
    "offense_pass_blocking_new = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking_new)\n",
    "offense_run_blocking_new = create_prefix(prefix=\"run_block_\", df=offense_run_blocking_new)\n",
    "\n",
    "\n",
    "pass_rush_summary_new = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary_new)\n",
    "run_defense_summary_new = create_prefix(prefix=\"run_defense_\", df=run_defense_summary_new)\n",
    "defense_coverage_scheme_new = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme_new)\n",
    "defense_coverage_summary_new = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary_new)\n",
    "slot_coverage_new= create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>player</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense</th>\n",
       "      <th>def_summary_snap_counts_slot</th>\n",
       "      <th>def_summary_stops</th>\n",
       "      <th>def_summary_tackles</th>\n",
       "      <th>def_summary_targets</th>\n",
       "      <th>def_summary_total_pressures</th>\n",
       "      <th>def_summary_touchdowns</th>\n",
       "      <th>def_summary_yards</th>\n",
       "      <th>def_summary_yards_after_catch</th>\n",
       "      <th>def_summary_yards_per_reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>kylehamilton_bal_2022_9</td>\n",
       "      <td>kylehamilton</td>\n",
       "      <td>kylehamilton_bal_2022</td>\n",
       "      <td>bal_2022_9</td>\n",
       "      <td>bal_2022</td>\n",
       "      <td>102684</td>\n",
       "      <td>s</td>\n",
       "      <td>bal</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>rodneythomasii_ind_2022_9</td>\n",
       "      <td>rodneythomasii</td>\n",
       "      <td>rodneythomasii_ind_2022</td>\n",
       "      <td>ind_2022_9</td>\n",
       "      <td>ind_2022</td>\n",
       "      <td>108389</td>\n",
       "      <td>s</td>\n",
       "      <td>ind</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>deealford_atl_2022_9</td>\n",
       "      <td>deealford</td>\n",
       "      <td>deealford_atl_2022</td>\n",
       "      <td>atl_2022_9</td>\n",
       "      <td>atl_2022</td>\n",
       "      <td>110542</td>\n",
       "      <td>cb</td>\n",
       "      <td>atl</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>domeniquedavis_cin_2022_9</td>\n",
       "      <td>domeniquedavis</td>\n",
       "      <td>domeniquedavis_cin_2022</td>\n",
       "      <td>cin_2022_9</td>\n",
       "      <td>cin_2022</td>\n",
       "      <td>112887</td>\n",
       "      <td>di</td>\n",
       "      <td>cin</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>kaderkohou_mia_2022_9</td>\n",
       "      <td>kaderkohou</td>\n",
       "      <td>kaderkohou_mia_2022</td>\n",
       "      <td>mia_2022_9</td>\n",
       "      <td>mia_2022</td>\n",
       "      <td>156070</td>\n",
       "      <td>cb</td>\n",
       "      <td>mia</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p_id          player           player_team_id  \\\n",
       "653    kylehamilton_bal_2022_9    kylehamilton    kylehamilton_bal_2022   \n",
       "654  rodneythomasii_ind_2022_9  rodneythomasii  rodneythomasii_ind_2022   \n",
       "655       deealford_atl_2022_9       deealford       deealford_atl_2022   \n",
       "656  domeniquedavis_cin_2022_9  domeniquedavis  domeniquedavis_cin_2022   \n",
       "657      kaderkohou_mia_2022_9      kaderkohou      kaderkohou_mia_2022   \n",
       "\n",
       "    unique_team_id team_id_impute  numeric_id position team_name  year week  \\\n",
       "653     bal_2022_9       bal_2022      102684        s       bal  2022    9   \n",
       "654     ind_2022_9       ind_2022      108389        s       ind  2022    9   \n",
       "655     atl_2022_9       atl_2022      110542       cb       atl  2022    9   \n",
       "656     cin_2022_9       cin_2022      112887       di       cin  2022    9   \n",
       "657     mia_2022_9       mia_2022      156070       cb       mia  2022    9   \n",
       "\n",
       "     ...  def_summary_snap_counts_run_defense  def_summary_snap_counts_slot  \\\n",
       "653  ...                                    0                             0   \n",
       "654  ...                                    0                             0   \n",
       "655  ...                                    0                             0   \n",
       "656  ...                                    0                             0   \n",
       "657  ...                                    0                             0   \n",
       "\n",
       "     def_summary_stops  def_summary_tackles  def_summary_targets  \\\n",
       "653                  0                    0                    0   \n",
       "654                  0                    0                    0   \n",
       "655                  0                    0                    0   \n",
       "656                  0                    0                    0   \n",
       "657                  0                    0                    0   \n",
       "\n",
       "     def_summary_total_pressures  def_summary_touchdowns  def_summary_yards  \\\n",
       "653                            0                       0                  0   \n",
       "654                            0                       0                  0   \n",
       "655                            0                       0                  0   \n",
       "656                            0                       0                  0   \n",
       "657                            0                       0                  0   \n",
       "\n",
       "     def_summary_yards_after_catch  def_summary_yards_per_reception  \n",
       "653                              0                                0  \n",
       "654                              0                                0  \n",
       "655                              0                                0  \n",
       "656                              0                                0  \n",
       "657                              0                                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring the historic and new player pool data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0)\n",
    "\n",
    "\n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0)\n",
    "\n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0)\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0)\n",
    "\n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0)\n",
    "\n",
    "\n",
    "### after the concat cell ###\n",
    "passing_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_allowed_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "time_in_pocket.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "\n",
    "rec_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "rush_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "block_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_pass_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_run_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "def_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "pass_rush_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "run_defense_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "slot_coverage.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "st_kickers.drop_duplicates(subset='p_id', inplace=True)\n",
    "st_punters.drop_duplicates(subset='p_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rolling function and pass pff datasets through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 21s, sys: 475 ms, total: 7min 22s\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def rolling(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"player\",\"team_name\",\"year\",\"week\"], ascending=[True, True, True, True])\n",
    "    data['week']=data['week'].apply(str)\n",
    "    data['year']=data['year'].apply(str)\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        #roll5 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        #roll4 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll3 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "   \n",
    "passing_depth_roll = rolling(data=passing_depth, roll_value=3, roll_type='mean')\n",
    "passing_allowed_pressure_roll = rolling(data=passing_allowed_pressure, roll_value=3, roll_type='mean')\n",
    "passing_pressure_roll = rolling(data=passing_pressure, roll_value=3, roll_type='mean')\n",
    "passing_concept_roll = rolling(data=passing_concept, roll_value=3, roll_type='mean')\n",
    "time_in_pocket_roll = rolling(data=time_in_pocket, roll_value=3, roll_type='mean')\n",
    "passing_summ_conc_roll = rolling(data=passing_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "\n",
    "rec_summ_conc_roll = rolling(data=rec_summ_conc, roll_value=3, roll_type='mean')\n",
    "receiving_concept_roll =rolling(data=receiving_concept, roll_value=3, roll_type='mean')\n",
    "receiving_depth_roll = rolling(data=receiving_depth, roll_value=3, roll_type='mean')\n",
    "receiving_scheme_roll = rolling(data=receiving_scheme, roll_value=3, roll_type='mean')\n",
    "\n",
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "block_summ_conc_roll = rolling(data=block_summ_conc, roll_value=3, roll_type='mean')\n",
    "offense_pass_blocking_roll = rolling(data=offense_pass_blocking, roll_value=3, roll_type='mean')\n",
    "offense_run_blocking_roll = rolling(data=offense_run_blocking, roll_value=3, roll_type='mean')\n",
    "\n",
    "def_summ_conc_roll = rolling(data=def_summ_conc, roll_value=3, roll_type='mean')\n",
    "pass_rush_summary_roll = rolling(data=pass_rush_summary, roll_value=3, roll_type='mean')\n",
    "run_defense_summary_roll = rolling(data=run_defense_summary, roll_value=3, roll_type='mean')\n",
    "defense_coverage_scheme_roll = rolling(data=defense_coverage_scheme, roll_value=3, roll_type='mean')\n",
    "defense_coverage_summary_roll = rolling(data=defense_coverage_summary, roll_value=3, roll_type='mean')\n",
    "slot_coverage_roll = rolling(data=slot_coverage, roll_value=3, roll_type='mean')\n",
    "\n",
    "st_kickers_roll = rolling(data=st_kickers, roll_value=3, roll_type='mean')\n",
    "st_punters_roll = rolling(data=st_punters, roll_value=3, roll_type='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Create better imputation function before weighting team_position_group functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter_fillna(df=None, position=None, min_Var=None):\n",
    "    sub= df[df['position'].str.match(position)]\n",
    "    sub_limit = sub[(sub[min_Var] <=5) & (sub[min_Var] >=1)]\n",
    "    buckup_df = pd.DataFrame(sub_limit.median()).T\n",
    "    num_cols = sub.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    msk = sub.isnull()\n",
    "    tmp = sub[num_cols].mask(msk, buckup_df[num_cols])\n",
    "    tmp = np.where(msk[num_cols], buckup_df[num_cols], tmp[num_cols])\n",
    "    tmp = pd.DataFrame(tmp, columns=buckup_df.columns)\n",
    "    ids = pd.DataFrame(sub.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "    mrg = pd.concat([ids, tmp], axis=1)\n",
    "    return mrg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.2 s, sys: 144 ms, total: 44.3 s\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.median()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth_roll = impute(passing_depth_roll)\n",
    "passing_allowed_pressure_roll = impute(passing_allowed_pressure_roll)\n",
    "passing_pressure_roll = impute(passing_pressure_roll)\n",
    "passing_concept_roll = impute(passing_concept_roll)\n",
    "time_in_pocket_roll = impute(time_in_pocket_roll)\n",
    "passing_summ_conc_roll = impute(passing_summ_conc_roll)\n",
    "\n",
    "rec_summ_conc_roll = impute(rec_summ_conc_roll)\n",
    "receiving_concept_roll = impute(receiving_concept_roll)\n",
    "receiving_depth_roll = impute(receiving_depth_roll)\n",
    "receiving_scheme_roll = impute(receiving_scheme_roll)\n",
    "\n",
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)\n",
    "\n",
    "block_summ_conc_roll = impute(block_summ_conc_roll)\n",
    "offense_pass_blocking_roll = impute(offense_pass_blocking_roll)\n",
    "offense_run_blocking_roll = impute(offense_run_blocking_roll)\n",
    "\n",
    "def_summ_conc_roll = impute(def_summ_conc_roll)\n",
    "pass_rush_summary_roll = impute(pass_rush_summary_roll)\n",
    "run_defense_summary_roll = impute(run_defense_summary_roll)\n",
    "defense_coverage_scheme_roll = impute(defense_coverage_scheme_roll)\n",
    "defense_coverage_summary_roll = impute(defense_coverage_summary_roll)\n",
    "slot_coverage_roll = impute(slot_coverage_roll)\n",
    "\n",
    "st_kickers_roll = impute(st_kickers_roll)\n",
    "st_punters_roll = impute(st_punters_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "biometrics = pd.read_csv('./other_data/2022_imputed_combine.csv')\n",
    "biometrics=biometrics[['player_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "biometrics['position']=biometrics['position'].apply(str)\n",
    "\n",
    "\n",
    "qb_bio = biometrics[biometrics['position'].isin(['qb'])]\n",
    "rb_bio = biometrics[biometrics['position'].isin(['hb','qb','fb','wr'])]\n",
    "rec_bio = biometrics[biometrics['position'].isin(['wr','te','hb'])]\n",
    "ol_bio = biometrics[biometrics['position'].isin(['ol','te'])]\n",
    "def_bio_dl = biometrics[biometrics['position'].isin(['dl'])]\n",
    "def_bio_db = biometrics[biometrics['position'].isin(['db'])]\n",
    "def_bio_lb = biometrics[biometrics['position'].isin(['lb'])]\n",
    "st_bio = biometrics[biometrics['position'].isin(['st'])]\n",
    "\n",
    "qb_median = qb_bio.groupby(['position']).median().reset_index()\n",
    "rb_median = rb_bio.groupby(['position']).median().reset_index()\n",
    "rec_median = rec_bio.groupby(['position']).median().reset_index()\n",
    "ol_median = ol_bio.groupby(['position']).median().reset_index()\n",
    "dl_median = def_bio_dl.groupby(['position']).median().reset_index()\n",
    "db_median = def_bio_db.groupby(['position']).median().reset_index()\n",
    "lb_median = def_bio_lb.groupby(['position']).median().reset_index()\n",
    "st_median = st_bio.groupby(['position']).median().reset_index()\n",
    "\n",
    "\n",
    "qb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rec_bio.drop(['position'], axis=1, inplace=True)\n",
    "ol_bio.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_dl.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_db.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_lb.drop(['position'], axis=1, inplace=True)\n",
    "st_bio.drop(['position'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position ##\n",
    "rush_summ_conc_roll['position'] = rush_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "temp_fillna_df = pd.merge(rush_summ_conc_roll, rb_median, on='position', how='left')\n",
    "rush_summ_conc_roll = pd.merge(rush_summ_conc_roll, rb_bio, on='player_team_id', how='left')\n",
    "rush_summ_conc_roll = rush_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- qb ##\n",
    "temp_fillna_df = pd.merge(passing_summ_conc_roll, qb_median, on='position', how='left')\n",
    "passing_summ_conc_roll = pd.merge(passing_summ_conc_roll, qb_bio, on='player_team_id', how='left')\n",
    "passing_summ_conc_roll = passing_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "rec_summ_conc_roll['position'] = rec_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "temp_fillna_df = pd.merge(rec_summ_conc_roll, rec_median, on='position', how='left')\n",
    "rec_summ_conc_roll = pd.merge(rec_summ_conc_roll, rec_bio, on='player_team_id', how='left')\n",
    "rec_summ_conc_roll = rec_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "block_summ_conc_roll=block_summ_conc_roll[block_summ_conc_roll['position'] != 'cb']\n",
    "block_summ_conc_roll['position'] = block_summ_conc_roll['position'].str.replace('t','ol')\n",
    "block_summ_conc_roll['position'] = block_summ_conc_roll['position'].str.replace('g','ol')\n",
    "temp_fillna_df = pd.merge(block_summ_conc_roll , ol_median, on='position', how='left')\n",
    "block_summ_conc_roll = pd.merge(block_summ_conc_roll, ol_bio, on='player_team_id', how='left')\n",
    "block_summ_conc_roll = block_summ_conc_roll.combine_first(temp_fillna_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine players for each dataset into team_year_week groupings\n",
    "\n",
    "### These next few cells will compute weighted averages based on average snaps played.  The first function will default snaps to 1 if snap value is 0.  The rest of the functions are dataset specific and will compute the weighted averages based on rollup aaverages and snaps played.\n",
    "\n",
    "#### For example: Washington had 5 rbs player in the last 3 games.  It doesn't make sense to weight all the players stats into a single average if 3 of those backs only averaged 2 snaps and rushed for 2 yards whereas B. Robinson averages 18 snaps and rushes for 65 yards and Gibson averages 10 snaps for 40 yards.  Therefore we weight each players rolling average based on their rolling snaps played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rushing weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rush_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rush_summ_conc_roll['rush_summary_attempts'] = rush_summ_conc_roll.apply(lambda df: rush_att(df, var='rush_summary_attempts'), axis=1)   \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rush_summary_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "\n",
    "rb_stats = rush_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "rb_stats.tail(n=10)\n",
    "rb_stats = rb_stats.rename(columns={c: c+'_rush' for c in rb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_rush</th>\n",
       "      <th>rush_summary_attempts_rush</th>\n",
       "      <th>rush_summary_avoided_tackles_rush</th>\n",
       "      <th>rush_summary_breakaway_attempts_rush</th>\n",
       "      <th>rush_summary_breakaway_percent_rush</th>\n",
       "      <th>rush_summary_breakaway_yards_rush</th>\n",
       "      <th>rush_summary_declined_penalties_rush</th>\n",
       "      <th>rush_summary_designed_yards_rush</th>\n",
       "      <th>rush_summary_drops_rush</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_rush</th>\n",
       "      <th>vertical_rush</th>\n",
       "      <th>broad_jump_rush</th>\n",
       "      <th>shuttle_rush</th>\n",
       "      <th>3cone_rush</th>\n",
       "      <th>explosive_rush</th>\n",
       "      <th>size_speed_rush</th>\n",
       "      <th>draft_yr_rush</th>\n",
       "      <th>round_rush</th>\n",
       "      <th>selection_rush</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9443.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>33.343092</td>\n",
       "      <td>116.765496</td>\n",
       "      <td>4.379620</td>\n",
       "      <td>7.141241</td>\n",
       "      <td>22.142675</td>\n",
       "      <td>0.269236</td>\n",
       "      <td>2010.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>105.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>7422.375000</td>\n",
       "      <td>17.173611</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>16.173611</td>\n",
       "      <td>13.694444</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>61.482639</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>16.677083</td>\n",
       "      <td>33.326686</td>\n",
       "      <td>119.628228</td>\n",
       "      <td>4.244087</td>\n",
       "      <td>6.990571</td>\n",
       "      <td>20.851431</td>\n",
       "      <td>0.259650</td>\n",
       "      <td>2012.177083</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>167.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>7569.011364</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>16.286350</td>\n",
       "      <td>13.621212</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>47.628788</td>\n",
       "      <td>0.486742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.874999</td>\n",
       "      <td>33.011364</td>\n",
       "      <td>118.568182</td>\n",
       "      <td>4.266250</td>\n",
       "      <td>7.014091</td>\n",
       "      <td>20.799706</td>\n",
       "      <td>0.263818</td>\n",
       "      <td>2012.454545</td>\n",
       "      <td>5.431818</td>\n",
       "      <td>165.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>7464.839080</td>\n",
       "      <td>14.340996</td>\n",
       "      <td>1.750958</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17.778791</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.938697</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>...</td>\n",
       "      <td>17.057471</td>\n",
       "      <td>32.873563</td>\n",
       "      <td>118.068966</td>\n",
       "      <td>4.275747</td>\n",
       "      <td>7.010000</td>\n",
       "      <td>20.730068</td>\n",
       "      <td>0.265894</td>\n",
       "      <td>2012.310345</td>\n",
       "      <td>5.321839</td>\n",
       "      <td>161.195402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>7676.854839</td>\n",
       "      <td>12.505376</td>\n",
       "      <td>1.263441</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>10.233871</td>\n",
       "      <td>4.295699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.174731</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>...</td>\n",
       "      <td>16.387096</td>\n",
       "      <td>33.370968</td>\n",
       "      <td>119.629032</td>\n",
       "      <td>4.243226</td>\n",
       "      <td>6.994032</td>\n",
       "      <td>20.798298</td>\n",
       "      <td>0.258659</td>\n",
       "      <td>2012.564516</td>\n",
       "      <td>5.612903</td>\n",
       "      <td>175.096774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_rush  rush_summary_attempts_rush  \\\n",
       "0     ari_2014_1      9443.000000                    4.000000   \n",
       "1    ari_2014_10      7422.375000                   17.173611   \n",
       "2    ari_2014_11      7569.011364                   15.750000   \n",
       "3    ari_2014_12      7464.839080                   14.340996   \n",
       "4    ari_2014_13      7676.854839                   12.505376   \n",
       "\n",
       "   rush_summary_avoided_tackles_rush  rush_summary_breakaway_attempts_rush  \\\n",
       "0                           0.666667                              0.000000   \n",
       "1                           0.958333                              0.708333   \n",
       "2                           0.886364                              0.704545   \n",
       "3                           1.750958                              0.666667   \n",
       "4                           1.263441                              0.252688   \n",
       "\n",
       "   rush_summary_breakaway_percent_rush  rush_summary_breakaway_yards_rush  \\\n",
       "0                             0.000000                           0.000000   \n",
       "1                            16.173611                          13.694444   \n",
       "2                            16.286350                          13.621212   \n",
       "3                            17.778791                          12.000000   \n",
       "4                            10.233871                           4.295699   \n",
       "\n",
       "   rush_summary_declined_penalties_rush  rush_summary_designed_yards_rush  \\\n",
       "0                              0.000000                         16.333333   \n",
       "1                              0.046875                         61.482639   \n",
       "2                              0.026515                         47.628788   \n",
       "3                              0.000000                         38.938697   \n",
       "4                              0.000000                         23.174731   \n",
       "\n",
       "   rush_summary_drops_rush  ...  bench_rush  vertical_rush  broad_jump_rush  \\\n",
       "0                 0.000000  ...   17.600000      33.343092       116.765496   \n",
       "1                 0.708333  ...   16.677083      33.326686       119.628228   \n",
       "2                 0.486742  ...   16.874999      33.011364       118.568182   \n",
       "3                 0.011494  ...   17.057471      32.873563       118.068966   \n",
       "4                 0.505376  ...   16.387096      33.370968       119.629032   \n",
       "\n",
       "   shuttle_rush  3cone_rush  explosive_rush  size_speed_rush  draft_yr_rush  \\\n",
       "0      4.379620    7.141241       22.142675         0.269236    2010.200000   \n",
       "1      4.244087    6.990571       20.851431         0.259650    2012.177083   \n",
       "2      4.266250    7.014091       20.799706         0.263818    2012.454545   \n",
       "3      4.275747    7.010000       20.730068         0.265894    2012.310345   \n",
       "4      4.243226    6.994032       20.798298         0.258659    2012.564516   \n",
       "\n",
       "   round_rush  selection_rush  \n",
       "0    3.800000      105.800000  \n",
       "1    5.416667      167.937500  \n",
       "2    5.431818      165.295455  \n",
       "3    5.321839      161.195402  \n",
       "4    5.612903      175.096774  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Passing weight average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def pass_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "passing_summ_conc_roll['pass_summary_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_summary_dropbacks'), axis=1)\n",
    "passing_depth_roll['pass_depth_base_dropbacks'] = passing_depth_roll.apply(lambda df: pass_att(df, var='pass_depth_base_dropbacks'), axis=1)  \n",
    "passing_pressure_roll['pass_under_pressure_base_dropbacks'] = passing_pressure_roll.apply(lambda df: pass_att(df, var='pass_under_pressure_base_dropbacks'), axis=1)  \n",
    "passing_allowed_pressure_roll['pressure_source_allowed_pressure_dropbacks'] = passing_allowed_pressure_roll.apply(lambda df: pass_att(df, var='pressure_source_allowed_pressure_dropbacks'), axis=1)  \n",
    "#passing_concept_roll['pass_concept_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_concept_dropbacks'), axis=1)  \n",
    "time_in_pocket_roll['pass_time_dropbacks'] = time_in_pocket_roll.apply(lambda df: pass_att(df, var='pass_time_dropbacks'), axis=1)     \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_summary_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "qb_stats = passing_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_depth_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_depth_stats = passing_depth_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pressure_source_allowed_pressure_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_allowed_pressure_stats = passing_allowed_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_under_pressure_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_pressure_stats = passing_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_concept_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_concept_stats = passing_concept_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_time_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "time_in_pocke_stats = time_in_pocket_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "qb_stats = qb_stats.rename(columns={c: c+'_passing' for c in qb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_passing</th>\n",
       "      <th>pass_summary_accuracy_percent_passing</th>\n",
       "      <th>pass_summary_aimed_passes_passing</th>\n",
       "      <th>pass_summary_attempts_passing</th>\n",
       "      <th>pass_summary_avg_depth_of_target_passing</th>\n",
       "      <th>pass_summary_avg_time_to_throw_passing</th>\n",
       "      <th>pass_summary_bats_passing</th>\n",
       "      <th>pass_summary_big_time_throws_passing</th>\n",
       "      <th>pass_summary_btt_rate_passing</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_passing</th>\n",
       "      <th>vertical_passing</th>\n",
       "      <th>broad_jump_passing</th>\n",
       "      <th>shuttle_passing</th>\n",
       "      <th>3cone_passing</th>\n",
       "      <th>explosive_passing</th>\n",
       "      <th>size_speed_passing</th>\n",
       "      <th>draft_yr_passing</th>\n",
       "      <th>round_passing</th>\n",
       "      <th>selection_passing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>7102.000000</td>\n",
       "      <td>74.766667</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.533333</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.999999</td>\n",
       "      <td>33.215461</td>\n",
       "      <td>122.827481</td>\n",
       "      <td>4.168103</td>\n",
       "      <td>6.896206</td>\n",
       "      <td>22.696851</td>\n",
       "      <td>0.266665</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>2402.317073</td>\n",
       "      <td>69.817886</td>\n",
       "      <td>29.861789</td>\n",
       "      <td>32.731707</td>\n",
       "      <td>10.781301</td>\n",
       "      <td>2.512520</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>2.227642</td>\n",
       "      <td>5.682927</td>\n",
       "      <td>...</td>\n",
       "      <td>23.536585</td>\n",
       "      <td>31.957077</td>\n",
       "      <td>115.956210</td>\n",
       "      <td>4.280201</td>\n",
       "      <td>6.837720</td>\n",
       "      <td>21.078042</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>2004.853659</td>\n",
       "      <td>1.463415</td>\n",
       "      <td>20.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>65.733333</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>15.266667</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>67.866667</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>72.566667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>13.466667</td>\n",
       "      <td>2.696667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>6.770000</td>\n",
       "      <td>19.203633</td>\n",
       "      <td>0.300984</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_passing  pass_summary_accuracy_percent_passing  \\\n",
       "0     ari_2014_1         7102.000000                              74.766667   \n",
       "1    ari_2014_10         2402.317073                              69.817886   \n",
       "2    ari_2014_11         3659.000000                              65.733333   \n",
       "3    ari_2014_12         3659.000000                              67.866667   \n",
       "4    ari_2014_13         3659.000000                              72.566667   \n",
       "\n",
       "   pass_summary_aimed_passes_passing  pass_summary_attempts_passing  \\\n",
       "0                          30.666667                      33.000000   \n",
       "1                          29.861789                      32.731707   \n",
       "2                          19.333333                      21.333333   \n",
       "3                          19.333333                      21.000000   \n",
       "4                          19.666667                      21.000000   \n",
       "\n",
       "   pass_summary_avg_depth_of_target_passing  \\\n",
       "0                                  8.533333   \n",
       "1                                 10.781301   \n",
       "2                                 15.266667   \n",
       "3                                 13.466667   \n",
       "4                                 13.466667   \n",
       "\n",
       "   pass_summary_avg_time_to_throw_passing  pass_summary_bats_passing  \\\n",
       "0                                2.660000                   0.333333   \n",
       "1                                2.512520                   0.821138   \n",
       "2                                2.570000                   0.666667   \n",
       "3                                2.520000                   0.333333   \n",
       "4                                2.696667                   0.666667   \n",
       "\n",
       "   pass_summary_big_time_throws_passing  pass_summary_btt_rate_passing  ...  \\\n",
       "0                              1.333333                       3.800000  ...   \n",
       "1                              2.227642                       5.682927  ...   \n",
       "2                              1.333333                       9.433333  ...   \n",
       "3                              0.333333                       6.666667  ...   \n",
       "4                              0.333333                       6.666667  ...   \n",
       "\n",
       "   bench_passing  vertical_passing  broad_jump_passing  shuttle_passing  \\\n",
       "0      23.999999         33.215461          122.827481         4.168103   \n",
       "1      23.536585         31.957077          115.956210         4.280201   \n",
       "2      23.000000         30.500000          108.000000         4.410000   \n",
       "3      23.000000         30.500000          108.000000         4.410000   \n",
       "4      23.000000         30.500000          108.000000         4.410000   \n",
       "\n",
       "   3cone_passing  explosive_passing  size_speed_passing  draft_yr_passing  \\\n",
       "0       6.896206          22.696851            0.266665       2003.000000   \n",
       "1       6.837720          21.078042            0.282569       2004.853659   \n",
       "2       6.770000          19.203633            0.300984       2007.000000   \n",
       "3       6.770000          19.203633            0.300984       2007.000000   \n",
       "4       6.770000          19.203633            0.300984       2007.000000   \n",
       "\n",
       "   round_passing  selection_passing  \n",
       "0       1.000000           1.000000  \n",
       "1       1.463415          20.463415  \n",
       "2       2.000000          43.000000  \n",
       "3       2.000000          43.000000  \n",
       "4       2.000000          43.000000  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute receiver weighted average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rec_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rec_summ_conc_roll['rec_summary_targets'] = rec_summ_conc_roll.apply(lambda df: rec_att(df, var='rec_summary_targets'), axis=1)   \n",
    "receiving_concept_roll['rec_concept_base_targets'] = receiving_concept_roll.apply(lambda df: rec_att(df, var='rec_concept_base_targets'), axis=1) \n",
    "receiving_depth_roll['rec_depth_base_targets'] = receiving_depth_roll.apply(lambda df: rec_att(df, var='rec_depth_base_targets'), axis=1) \n",
    "receiving_scheme_roll['rec_scheme_base_targets'] = receiving_scheme_roll.apply(lambda df: rec_att(df, var='rec_scheme_base_targets'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_summary_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "rec_stats = rec_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_concept_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_concept = receiving_concept.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_depth_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_depth = receiving_depth.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_scheme_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_scheme = receiving_scheme.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "rec_stats = rec_stats.rename(columns={c: c+'_rec' for c in rec_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute OL weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def snap_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "block_summ_conc_roll['block_summary_snap_counts_offense'] = block_summ_conc_roll.apply(lambda df: snap_fix(df, var='block_summary_snap_counts_offense'), axis=1)\n",
    "offense_pass_blocking_roll['pass_block_snap_counts_pass_block'] = offense_pass_blocking_roll.apply(lambda df: snap_fix(df, var='pass_block_snap_counts_pass_block'), axis=1) \n",
    "offense_run_blocking_roll['run_block_snap_counts_run_block'] = offense_run_blocking_roll.apply(lambda df: snap_fix(df, var='run_block_snap_counts_run_block'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='block_summary_snap_counts_offense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "ol_stats = block_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_block_snap_counts_pass_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_pass_blocking_roll = offense_pass_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='run_block_snap_counts_run_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_run_blocking_roll = offense_run_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "ol_stats = ol_stats.rename(columns={c: c+'_block' for c in ol_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "di    19627\n",
       "ed    17848\n",
       "cb    17250\n",
       "lb    15271\n",
       "s     14267\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_roll.position.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dl    5082\n",
       "db    4783\n",
       "ol    4748\n",
       "wr    3331\n",
       "hb    2658\n",
       "lb    2527\n",
       "te    1903\n",
       "qb    1294\n",
       "st     352\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometrics.position.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute defensive weighted averages datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_def_stats</th>\n",
       "      <th>def_summary_assists_def_stats</th>\n",
       "      <th>def_summary_batted_passes_def_stats</th>\n",
       "      <th>def_summary_catch_rate_def_stats</th>\n",
       "      <th>def_summary_declined_penalties_def_stats</th>\n",
       "      <th>def_summary_forced_fumbles_def_stats</th>\n",
       "      <th>def_summary_franchise_id_def_stats</th>\n",
       "      <th>def_summary_grades_coverage_defense_def_stats</th>\n",
       "      <th>def_summary_grades_defense_def_stats</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense_def_stats</th>\n",
       "      <th>def_summary_snap_counts_slot_def_stats</th>\n",
       "      <th>def_summary_stops_def_stats</th>\n",
       "      <th>def_summary_tackles_def_stats</th>\n",
       "      <th>def_summary_targets_def_stats</th>\n",
       "      <th>def_summary_total_pressures_def_stats</th>\n",
       "      <th>def_summary_touchdowns_def_stats</th>\n",
       "      <th>def_summary_yards_def_stats</th>\n",
       "      <th>def_summary_yards_after_catch_def_stats</th>\n",
       "      <th>def_summary_yards_per_reception_def_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9177.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.254045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.581579</td>\n",
       "      <td>61.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>11.361218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>5453.149401</td>\n",
       "      <td>0.380565</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>73.247643</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.769958</td>\n",
       "      <td>64.293564</td>\n",
       "      <td>...</td>\n",
       "      <td>16.002283</td>\n",
       "      <td>4.670234</td>\n",
       "      <td>1.309932</td>\n",
       "      <td>2.685502</td>\n",
       "      <td>2.461473</td>\n",
       "      <td>1.149258</td>\n",
       "      <td>0.061787</td>\n",
       "      <td>18.608019</td>\n",
       "      <td>8.409675</td>\n",
       "      <td>12.377799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>5259.055969</td>\n",
       "      <td>0.356216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.644115</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.691076</td>\n",
       "      <td>64.336686</td>\n",
       "      <td>...</td>\n",
       "      <td>17.159160</td>\n",
       "      <td>6.133217</td>\n",
       "      <td>1.411602</td>\n",
       "      <td>2.897683</td>\n",
       "      <td>2.704999</td>\n",
       "      <td>1.277511</td>\n",
       "      <td>0.092552</td>\n",
       "      <td>20.999708</td>\n",
       "      <td>11.907739</td>\n",
       "      <td>12.040963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>5382.830628</td>\n",
       "      <td>0.350820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.271848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030531</td>\n",
       "      <td>1.857766</td>\n",
       "      <td>63.717409</td>\n",
       "      <td>66.109632</td>\n",
       "      <td>...</td>\n",
       "      <td>16.160730</td>\n",
       "      <td>4.933366</td>\n",
       "      <td>1.549915</td>\n",
       "      <td>2.554963</td>\n",
       "      <td>2.191543</td>\n",
       "      <td>1.125596</td>\n",
       "      <td>0.050238</td>\n",
       "      <td>14.750303</td>\n",
       "      <td>9.143728</td>\n",
       "      <td>11.584772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>5510.920039</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>72.641086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>1.852601</td>\n",
       "      <td>62.197105</td>\n",
       "      <td>65.107514</td>\n",
       "      <td>...</td>\n",
       "      <td>16.156069</td>\n",
       "      <td>4.162974</td>\n",
       "      <td>1.693963</td>\n",
       "      <td>2.491169</td>\n",
       "      <td>1.885517</td>\n",
       "      <td>1.307001</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>15.314547</td>\n",
       "      <td>10.003051</td>\n",
       "      <td>11.376481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_def_stats  def_summary_assists_def_stats  \\\n",
       "0     ari_2014_1           9177.000000                       0.333333   \n",
       "1    ari_2014_10           5453.149401                       0.380565   \n",
       "2    ari_2014_11           5259.055969                       0.356216   \n",
       "3    ari_2014_12           5382.830628                       0.350820   \n",
       "4    ari_2014_13           5510.920039                       0.474310   \n",
       "\n",
       "   def_summary_batted_passes_def_stats  def_summary_catch_rate_def_stats  \\\n",
       "0                             0.000000                         70.254045   \n",
       "1                             0.021261                         73.247643   \n",
       "2                             0.000000                         70.644115   \n",
       "3                             0.000000                         69.271848   \n",
       "4                             0.056840                         72.641086   \n",
       "\n",
       "   def_summary_declined_penalties_def_stats  \\\n",
       "0                                  0.000000   \n",
       "1                                  0.040382   \n",
       "2                                  0.022154   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   def_summary_forced_fumbles_def_stats  def_summary_franchise_id_def_stats  \\\n",
       "0                              0.000000                           16.000000   \n",
       "1                              0.012700                            1.000000   \n",
       "2                              0.019968                            1.000000   \n",
       "3                              0.030531                            1.857766   \n",
       "4                              0.029383                            1.852601   \n",
       "\n",
       "   def_summary_grades_coverage_defense_def_stats  \\\n",
       "0                                      60.581579   \n",
       "1                                      63.769958   \n",
       "2                                      63.691076   \n",
       "3                                      63.717409   \n",
       "4                                      62.197105   \n",
       "\n",
       "   def_summary_grades_defense_def_stats  ...  \\\n",
       "0                             61.833333  ...   \n",
       "1                             64.293564  ...   \n",
       "2                             64.336686  ...   \n",
       "3                             66.109632  ...   \n",
       "4                             65.107514  ...   \n",
       "\n",
       "   def_summary_snap_counts_run_defense_def_stats  \\\n",
       "0                                      14.666667   \n",
       "1                                      16.002283   \n",
       "2                                      17.159160   \n",
       "3                                      16.160730   \n",
       "4                                      16.156069   \n",
       "\n",
       "   def_summary_snap_counts_slot_def_stats  def_summary_stops_def_stats  \\\n",
       "0                                0.666667                     1.000000   \n",
       "1                                4.670234                     1.309932   \n",
       "2                                6.133217                     1.411602   \n",
       "3                                4.933366                     1.549915   \n",
       "4                                4.162974                     1.693963   \n",
       "\n",
       "   def_summary_tackles_def_stats  def_summary_targets_def_stats  \\\n",
       "0                       2.000000                       0.666667   \n",
       "1                       2.685502                       2.461473   \n",
       "2                       2.897683                       2.704999   \n",
       "3                       2.554963                       2.191543   \n",
       "4                       2.491169                       1.885517   \n",
       "\n",
       "   def_summary_total_pressures_def_stats  def_summary_touchdowns_def_stats  \\\n",
       "0                               0.333333                          0.000000   \n",
       "1                               1.149258                          0.061787   \n",
       "2                               1.277511                          0.092552   \n",
       "3                               1.125596                          0.050238   \n",
       "4                               1.307001                          0.048170   \n",
       "\n",
       "   def_summary_yards_def_stats  def_summary_yards_after_catch_def_stats  \\\n",
       "0                     3.333333                                 1.333333   \n",
       "1                    18.608019                                 8.409675   \n",
       "2                    20.999708                                11.907739   \n",
       "3                    14.750303                                 9.143728   \n",
       "4                    15.314547                                10.003051   \n",
       "\n",
       "   def_summary_yards_per_reception_def_stats  \n",
       "0                                  11.361218  \n",
       "1                                  12.377799  \n",
       "2                                  12.040963  \n",
       "3                                  11.584772  \n",
       "4                                  11.376481  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def snap_fixs(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "def_summ_conc_roll['def_summary_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_run_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_run_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_pass_rush'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_pass_rush'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_coverage'), axis=1) \n",
    "\n",
    "\n",
    "pass_rush_summary_roll['pass_rush_snap_counts_pass_play'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='pass_rush_snap_counts_pass_play'), axis=1)\n",
    "run_defense_summary_roll['run_defense_snap_counts_run'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='run_defense_snap_counts_run'), axis=1)\n",
    "defense_coverage_scheme_roll['def_coverage_scheme_base_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_scheme_base_snap_counts_coverage'), axis=1)\n",
    "defense_coverage_summary_roll['def_coverage_summary_coverage_snaps_per_target'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_summary_coverage_snaps_per_target'), axis=1)\n",
    "slot_coverage_roll['def_slot_coverage_coverage_snaps'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_slot_coverage_coverage_snaps'), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Subset into defense positional groups ##\n",
    "def_rundef = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['ed','di','lb'])]\n",
    "def_passrush = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','ed','di'])]\n",
    "def_cov = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','cb','s'])]\n",
    "\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('di','dl')\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_rundef , dl_median, on='position', how='left')\n",
    "# def_rundef = pd.merge(def_rundef, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_rundef = def_rundef.combine_first(temp_fillna_df); def_rundef.head()\n",
    "\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('di','dl')\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_passrush , dl_median, on='position', how='left')\n",
    "# def_passrush = pd.merge(def_passrush, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_passrush = def_passrush.combine_first(temp_fillna_df); def_passrush.head()\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_stats = def_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_stats = def_stats.rename(columns={c: c+'_def_stats' for c in def_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_run_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_rundef = def_rundef.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_rundef = def_rundef.rename(columns={c: c+'_run_def' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_pass_rush'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_passrush = def_passrush.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_passrush = def_passrush.rename(columns={c: c+'_passrush' for c in def_passrush.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_cov = def_cov.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_cov = def_cov.rename(columns={c: c+'_def_cov' for c in def_cov.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_rush_snap_counts_pass_play'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_rush_stats = pass_rush_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='run_defense_snap_counts_run'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "run_defense_stats = run_defense_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_coverage_summary_coverage_snaps_per_target'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "defense_coverage_summary_stats = defense_coverage_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_coverage_scheme_base_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "defense_coverage_scheme_stats = defense_coverage_scheme_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='def_slot_coverage_coverage_snaps'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "slot_coverage_stats = slot_coverage_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "#def_stats = pd.merge(def_stats, def_rundef, on='unique_team_id', how='inner').merge(def_passrush, on='unique_team_id', how='inner').merge(def_cov, on='unique_team_id', how='inner')\n",
    "# def_rundef = def_rundef.rename(columns={c: c+'_rundef' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def_stats.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted(nData, snap_Var='def_slot_coverage_coverage_snaps'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "slot_coverage_stats = slot_coverage_roll.groupby('unique_team_id').apply(weighted).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute special teams weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_bio.columns = [str(col) + '_st' for col in st_bio.columns]\n",
    "# st_kickers_roll = pd.merge(st_kickers_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_kickers_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def kicks_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_kickers_roll['kicks'] = st_kickers_roll['kicking_pat_attempts']+st_kickers_roll['kicking_total_attempts']\n",
    "st_kickers_roll ['kicks'] = st_kickers_roll .apply(lambda df: snap_fixs(df, var='kicks'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='kicks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_kickers = st_kickers_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_punters_roll = pd.merge(st_punters_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_punters_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def punts_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_punters_roll['punting_attempts'] = st_punters_roll.apply(lambda df: snap_fixs(df, var='punting_attempts'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='punting_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_punters = st_punters_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling File and write out to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_vars = spread_comb[spread_comb['schedule_week'] != '1']\n",
    "\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id','score_home','score_away']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id','score_home','score_away']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'score_home',\n",
    "'score_away',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "\n",
    "dfs_list = [spread_ids,\n",
    "            tgs_roll,\n",
    "            fo_roll,\n",
    "            qb_stats,\n",
    "            rb_stats,\n",
    "            rec_stats,\n",
    "            ol_stats,\n",
    "           def_stats,\n",
    "           def_rundef,\n",
    "           def_cov,\n",
    "           def_passrush,\n",
    "           st_punters,\n",
    "           st_kickers]\n",
    "\n",
    "dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'],\n",
    "                                            how='left'), dfs_list)\n",
    "\n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "\n",
    "\n",
    "favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "dfs_team = dfs_team.rename(columns={c: c+'_fav' for c in dfs_team.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','home_score','away_score','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "not_fav_df = not_fav_df.rename(columns={c: c+'_dog' for c in not_fav_df.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "\n",
    "not_fav_df.drop(['unique_team_id','wl','score_away_dog','score_home_dog'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "#not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_team_id', 'home_matchup_id', 'score_home_fav', 'score_away_fav',\n",
       "       'wl', 'pf', 'pa', 'overall_performance_tgs_fav', 'offense_tgs_fav',\n",
       "       'pass_tgs_fav',\n",
       "       ...\n",
       "       'kicking_thirty_attempts_fav', 'kicking_thirty_made_fav',\n",
       "       'kicking_thirty_percent_fav', 'kicking_total_attempts_fav',\n",
       "       'kicking_total_made_fav', 'kicking_total_percent_fav',\n",
       "       'kicking_twenty_attempts_fav', 'kicking_twenty_made_fav',\n",
       "       'kicking_twenty_percent_fav', 'kicks_fav'],\n",
       "      dtype='object', length=474)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_team.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge files and write to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDER CONSTRUCTION: Creating function to create modeling file by user selected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id','score_home','score_away']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id','score_home','score_away']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'score_home',\n",
    "'score_away',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "sample=[spread_ids,\n",
    "            tgs_roll,\n",
    "            fo_roll,\n",
    "            qb_stats,\n",
    "            rb_stats,\n",
    "            rec_stats,\n",
    "            ol_stats,\n",
    "           def_stats,\n",
    "           def_rundef,\n",
    "           def_cov,\n",
    "           def_passrush,\n",
    "           st_punters,\n",
    "           st_kickers]\n",
    "           \n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "def build_model_dataset(data_list=None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data_list: User provides a list of dataframes in format - [df1, df2, df3...] to be used to create modeling dataset.\n",
    "        \n",
    "        Options: \n",
    "        Football Outsiders\n",
    "        fo_roll - \n",
    "        \n",
    "        PFF\n",
    "        -Team Game Summaries -\n",
    "        tgs_roll -\n",
    "\n",
    "        -Passing:\n",
    "        qb_stats -\n",
    "        passing_depth_stats -\n",
    "        passing_pressure_stats -\n",
    "        passing_allowed_pressure_stats -\n",
    "        passing_concept_stats -\n",
    "        time_in_pocket_stats -\n",
    "        \n",
    "        -Receiving:\n",
    "        rec_stats -\n",
    "        receiving_concept -\n",
    "        receiving_depth -\n",
    "        receiving_scheme -\n",
    "        \n",
    "        -Blocking:\n",
    "        ol_stats -\n",
    "        offense_pass_blocking_roll -\n",
    "        offense_run_blocking_roll -\n",
    "        \n",
    "        -Defense:\n",
    "        def_stats -\n",
    "        def_rundef -\n",
    "        def_passrush -\n",
    "        def_cov -\n",
    "        pass_rush_stats -\n",
    "        defense_coverage_summary_stats -\n",
    "        run_defense_stats -\n",
    "        defense_coverage_scheme_stats -\n",
    "        slot_coverage_stats -\n",
    "        \n",
    "        -Special Teams:\n",
    "        st_kickers -\n",
    "        st_punters - \n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_list = data_list\n",
    "    dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'], how='left'), dataset_list)\n",
    "    spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "    favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "    not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "    not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "    favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    return pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=[spread_ids,\n",
    "        passing_concept_stats,\n",
    "        defense_coverage_scheme_stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df=build_model_dataset(data_list=sample)\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.to_csv('./modeling_data/nfl_spreads_wconcept'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
