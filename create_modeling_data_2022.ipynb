{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import ascii_letters, digits\n",
    "import utils.cleaning_dicts\n",
    "#import matplotlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_w7.csv\t\t\t       other_data\r\n",
      "chromedriver\t\t\t       pfr\r\n",
      "create_modeling_data_2022.ipynb        rbbio.csv\r\n",
      "create_modeling_data_sample_all.ipynb  README.md\r\n",
      "create_player_pools_2022.ipynb\t       rushroll.csv\r\n",
      "current_data\t\t\t       scripts\r\n",
      "fo_addtohist_update.csv\t\t       spreads_data\r\n",
      "historic_data\t\t\t       sumconcrollrb.csv\r\n",
      "misc_files\t\t\t       update_spreads_file.py\r\n",
      "modeling_data\t\t\t       utils\r\n",
      "notebooks\t\t\t       weather_scraper_current_year.py\r\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.path.abspath(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT: Users must change the week values to the current week in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_week_int = 8\n",
    "cur_week_str = str(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in, clean and process all pff position datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "                ###   Read-in and clean all passing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "passing_depth = pd.read_csv('./historic_data/pff_data/passing_depth_hist.csv')\n",
    "passing_allowed_pressure = pd.read_csv('./historic_data/pff_data/passing_allowed_pressure_hist.csv')\n",
    "passing_pressure = pd.read_csv('./historic_data/pff_data/passing_pressure_hist.csv')\n",
    "passing_concept = pd.read_csv('./historic_data/pff_data/passing_concept_hist.csv')\n",
    "time_in_pocket = pd.read_csv('./historic_data/pff_data/time_in_pocket_hist.csv')\n",
    "passing_summ_conc = pd.read_csv('./historic_data/pff_data/passing_summ_conc_hist.csv')\n",
    "\n",
    "passing_depth_new = pd.read_csv('./scripts/nfl_all/passing_depth_2022.csv')\n",
    "passing_allowed_pressure_new = pd.read_csv('./scripts/nfl_all/passing_allowed_pressure_2022.csv')\n",
    "passing_pressure_new = pd.read_csv('./scripts/nfl_all/passing_pressure_2022.csv')\n",
    "passing_concept_new = pd.read_csv('./scripts/nfl_all/passing_concept_2022.csv')\n",
    "time_in_pocket_new = pd.read_csv('./scripts/nfl_all/time_in_pocket_2022.csv')\n",
    "passing_summ_conc_new = pd.read_csv('./scripts/nfl_all/passing_summ_conc_2022.csv')\n",
    "                                 \n",
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0).reset_index(drop=True)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0).reset_index(drop=True)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0).reset_index(drop=True)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0).reset_index(drop=True)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "\n",
    "def drop_non_qbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df=df[df['position'] == 'QB']\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "    \n",
    "passing_depth = drop_non_qbs(passing_depth)\n",
    "passing_allowed_pressure = drop_non_qbs(passing_allowed_pressure)\n",
    "passing_pressure = drop_non_qbs(passing_pressure)\n",
    "passing_concept = drop_non_qbs(passing_concept)\n",
    "time_in_pocket = drop_non_qbs(time_in_pocket)\n",
    "passing_summ_conc = drop_non_qbs(passing_summ_conc)\n",
    "\n",
    "\n",
    "passing_depth = passing_depth[passing_depth.columns.drop(list(passing_depth.filter(regex='left|right|center')))]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all receiving datasets ### scripts/nfl_all\n",
    "####################################################################################\n",
    "\n",
    "rec_summ_conc = pd.read_csv('./historic_data/pff_data/rec_summ_conc_hist.csv')\n",
    "receiving_concept = pd.read_csv('./historic_data/pff_data/receiving_concept_hist.csv')\n",
    "receiving_depth = pd.read_csv('./historic_data/pff_data/receiving_depth_hist.csv')\n",
    "receiving_scheme = pd.read_csv('./historic_data/pff_data/receiving_scheme_hist.csv')\n",
    "                                 \n",
    "rec_summ_conc_new = pd.read_csv('./scripts/nfl_all/rec_summ_conc_2022.csv')\n",
    "receiving_concept_new = pd.read_csv('./scripts/nfl_all/receiving_concept_2022.csv')\n",
    "receiving_depth_new = pd.read_csv('./scripts/nfl_all/receiving_depth_2022.csv')\n",
    "receiving_scheme_new = pd.read_csv('./scripts/nfl_all/receiving_scheme_2022.csv')\n",
    "                                 \n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0).reset_index(drop=True)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0).reset_index(drop=True)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0).reset_index(drop=True)                                 \n",
    "\n",
    "def drop_non_recs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|TE|HB|FB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    \n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rec_summ_conc = drop_non_recs(rec_summ_conc)\n",
    "receiving_concept = drop_non_recs(receiving_concept)\n",
    "receiving_depth = drop_non_recs(receiving_depth)\n",
    "receiving_scheme = drop_non_recs(receiving_scheme)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all rushing datasets ###\n",
    "####################################################################################\n",
    "\n",
    "rush_summ_conc = pd.read_csv('./historic_data/pff_data/rush_summ_conc_hist.csv')\n",
    "rush_summ_conc_new = pd.read_csv('./scripts/nfl_all/rush_summ_conc_2022.csv')                                 \n",
    "                                 \n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    " \n",
    "\n",
    "def drop_non_rbs(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df= df[df.position.str.match('WR|HB|FB|QB')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "rush_summ_conc = drop_non_rbs(rush_summ_conc)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all blocking datasets ###\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "block_summ_conc = pd.read_csv('./historic_data/pff_data/block_summ_conc_hist.csv')\n",
    "offense_pass_blocking = pd.read_csv('./historic_data/pff_data/offense_pass_blocking_hist.csv')\n",
    "offense_run_blocking = pd.read_csv('./historic_data/pff_data/offense_run_blocking_hist.csv')\n",
    "                                 \n",
    "block_summ_conc_new = pd.read_csv('./scripts/nfl_all/block_summ_conc_2022.csv')\n",
    "offense_pass_blocking_new = pd.read_csv('./scripts/nfl_all/offense_pass_blocking_2022.csv')\n",
    "offense_run_blocking_new = pd.read_csv('./scripts/nfl_all/offense_run_blocking_2022.csv')                                 \n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0).reset_index(drop=True)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "def drop_non_ols(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df = df[df['position'].notna()]\n",
    "    df= df[df.position.str.match('T|C|G|TE')]\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "\n",
    "block_summ_conc\t= drop_non_ols(block_summ_conc)\n",
    "offense_pass_blocking = drop_non_ols(offense_pass_blocking)\n",
    "offense_run_blocking = drop_non_ols(offense_run_blocking)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all defensive datasets ###\n",
    "####################################################################################\n",
    "\n",
    "def_summ_conc = pd.read_csv('./historic_data/pff_data/def_summ_conc_hist.csv')\n",
    "pass_rush_summary = pd.read_csv('./historic_data/pff_data/pass_rush_summary_hist.csv')\n",
    "run_defense_summary = pd.read_csv('./historic_data/pff_data/run_defense_summary_hist.csv')\n",
    "defense_coverage_scheme = pd.read_csv('./historic_data/pff_data/defense_coverage_scheme_hist.csv')\n",
    "defense_coverage_summary = pd.read_csv('./historic_data/pff_data/defense_coverage_summary_hist.csv')\n",
    "slot_coverage = pd.read_csv('./historic_data/pff_data/slot_coverage_hist.csv')\n",
    "                                 \n",
    "def_summ_conc_new = pd.read_csv('./scripts/nfl_all/def_summ_conc_2022.csv')\n",
    "pass_rush_summary_new = pd.read_csv('./scripts/nfl_all/pass_rush_summary_2022.csv')\n",
    "run_defense_summary_new = pd.read_csv('./scripts/nfl_all/run_defense_summary_2022.csv')\n",
    "defense_coverage_scheme_new = pd.read_csv('./scripts/nfl_all/defense_coverage_scheme_2022.csv')\n",
    "defense_coverage_summary_new = pd.read_csv('./scripts/nfl_all/defense_coverage_summary_2022.csv')\n",
    "slot_coverage_new = pd.read_csv('./scripts/nfl_all/slot_coverage_2022.csv')\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0).reset_index(drop=True)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0).reset_index(drop=True)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0).reset_index(drop=True)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0).reset_index(drop=True)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def drop_non_def(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "def_summ_conc = drop_non_def(def_summ_conc)\n",
    "pass_rush_summary = drop_non_def(pass_rush_summary)\n",
    "run_defense_summary = drop_non_def(run_defense_summary)\n",
    "defense_coverage_scheme = drop_non_def(defense_coverage_scheme)\n",
    "defense_coverage_summary = drop_non_def(defense_coverage_summary)\n",
    "slot_coverage = drop_non_def(slot_coverage)\n",
    "\n",
    "def_summ_conc=def_summ_conc[def_summ_conc['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "pass_rush_summary=pass_rush_summary[pass_rush_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\"])]\n",
    "run_defense_summary=run_defense_summary[run_defense_summary['position'].isin([\"ed\",\"lb\",\"di\",\"s\",\"cb\"])]\n",
    "defense_coverage_scheme=defense_coverage_scheme[defense_coverage_scheme['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "defense_coverage_summary=defense_coverage_summary[defense_coverage_summary['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "slot_coverage=slot_coverage[slot_coverage['position'].isin([\"lb\",\"s\",\"cb\"])]\n",
    "\n",
    "####################################################################################\n",
    "\t\t\t\t###   Read-in and clean all special teams datasets ###\n",
    "####################################################################################\t\n",
    "\n",
    "st_kickers = pd.read_csv('./historic_data/pff_data/st_kickers_hist.csv')\n",
    "st_punters = pd.read_csv('./historic_data/pff_data/st_punters_hist.csv')\n",
    "\n",
    "st_kickers_new = pd.read_csv('./scripts/nfl_all/st_kickers_2022.csv')\n",
    "st_punters_new = pd.read_csv('./scripts/nfl_all/st_punters_2022.csv')                                 \n",
    "                                 \n",
    "                                 \n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0).reset_index(drop=True)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0).reset_index(drop=True)\n",
    "                                 \n",
    "def clean_spec(df):\n",
    "    df=df.rename(columns={\"player_id\": \"numeric_id\"})\n",
    "    df['position']=df['position'].astype(str).str.lower()\n",
    "    df['team_name']=df['team_name'].astype(str).str.lower()       \n",
    "    df['player']=df['player'].str.replace('[^a-zA-Z0-9]', '').str.lower()\n",
    "    df['team_name']=df['team_name'].str.lower()\n",
    "    df['team_name']=df['team_name'].replace(\"oak\",\"lv\")\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "        ##  pass team name through dictionary to clean ##\n",
    "    df['team_name'] = df['team_name'].map(utils.cleaning_dicts.clean_team_pff).fillna(df['team_name'])\n",
    "    df['position'] = df['position'].map(utils.cleaning_dicts.pos_dict).fillna(df['position'])\n",
    "\n",
    "    \n",
    "    df.insert(0, \"p_id\", (df['player']+'_'+df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(2, \"player_team_id\", (df['player']+'_'+df['team_name']+'_'+df['year']))\n",
    "    df.insert(3, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    return df\n",
    "\n",
    "st_kickers =clean_spec(st_kickers)\n",
    "st_punters = clean_spec(st_punters)\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "####################################################################################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute all missing values in pff dataframe - NEED TO UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 247 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth = impute(passing_depth)\n",
    "passing_allowed_pressure = impute(passing_allowed_pressure)\n",
    "passing_pressure = impute(passing_pressure)\n",
    "passing_concept = impute(passing_concept)\n",
    "time_in_pocket = impute(time_in_pocket)\n",
    "passing_summ_conc = impute(passing_summ_conc)\n",
    "\n",
    "rec_summ_conc = impute(rec_summ_conc)\n",
    "receiving_concept = impute(receiving_concept)\n",
    "receiving_depth = impute(receiving_depth)\n",
    "receiving_scheme = impute(receiving_scheme)\n",
    "\n",
    "rush_summ_conc = impute(rush_summ_conc)\n",
    "\n",
    "block_summ_conc = impute(block_summ_conc)\n",
    "offense_pass_blocking = impute(offense_pass_blocking)\n",
    "offense_run_blocking = impute(offense_run_blocking)\n",
    "\n",
    "def_summ_conc = impute(def_summ_conc)\n",
    "pass_rush_summary = impute(pass_rush_summary)\n",
    "run_defense_summary = impute(run_defense_summary)\n",
    "defense_coverage_scheme = impute(defense_coverage_scheme)\n",
    "defense_coverage_summary = impute(defense_coverage_summary)\n",
    "slot_coverage = impute(slot_coverage)\n",
    "\n",
    "st_kickers = impute(st_kickers)\n",
    "st_punters = impute(st_punters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prefixes to all columns.  Creating column names structured as \"source-dataset_column-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc)\n",
    "rush_summ_conc = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc)\n",
    "rec_summ_conc = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc)\n",
    "block_summ_conc = id_prefix(prefix=\"block_summary_\", df=block_summ_conc)\n",
    "def_summ_conc = id_prefix(prefix=\"def_summary_\", df=def_summ_conc)\n",
    "st_kickers = id_prefix(prefix=\"kicking_\", df=st_kickers)\n",
    "st_punters = id_prefix(prefix=\"punting_\", df=st_punters)\n",
    "\n",
    "\n",
    "passing_depth = create_prefix(prefix=\"pass_depth_\", df=passing_depth)\n",
    "passing_allowed_pressure = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure)\n",
    "passing_pressure = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure)\n",
    "passing_concept = create_prefix(prefix=\"pass_concept_\", df=passing_concept)\n",
    "time_in_pocket = create_prefix(prefix=\"pass_time_\", df=time_in_pocket)\n",
    "\n",
    "\n",
    "receiving_concept = create_prefix(prefix=\"rec_concept_\", df=receiving_concept)\n",
    "receiving_depth = create_prefix(prefix=\"rec_depth_\", df=receiving_depth)\n",
    "receiving_scheme = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme)\n",
    "\n",
    "offense_pass_blocking = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking)\n",
    "offense_run_blocking = create_prefix(prefix=\"run_block_\", df=offense_run_blocking)\n",
    "\n",
    "\n",
    "pass_rush_summary = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary)\n",
    "run_defense_summary = create_prefix(prefix=\"run_defense_\", df=run_defense_summary)\n",
    "defense_coverage_scheme = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme)\n",
    "defense_coverage_summary = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary)\n",
    "slot_coverage = create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in weather data and clean raiders name - merged onto spreads data below ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in weather data###\n",
    "weather = pd.read_csv('./current_data/week_'+cur_week_str+'/weather_hist_all.csv')\n",
    "\n",
    "def raiders(df):\n",
    "    if 'oak' in str(df.away_matchup_id) and '2020' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2021' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    if 'oak' in str(df.away_matchup_id) and '2022' in str(df.away_matchup_id):\n",
    "        return df.away_matchup_id.replace(\"oak\",\"lv\")\n",
    "    else:\n",
    "        return df.away_matchup_id\n",
    "weather['away_matchup_id'] = weather.apply(lambda df: raiders(df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spreads data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t###   spreads data cleaning and engineering ###\n",
    "####################################################################################\n",
    "\n",
    "spreads = pd.read_csv('./current_data/week_'+cur_week_str+'/spreadsw'+cur_week_str+'.csv')\n",
    "\n",
    "new_acc = {'oak':'lv',\n",
    "          'sd':'lac',\n",
    "          'stl':'lar'}  \n",
    "\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].map(new_acc).fillna(spreads['team_home_abb'])\n",
    "spreads['away_team_abb'] = spreads['away_team_abb'].map(new_acc).fillna(spreads['away_team_abb']) \n",
    "\n",
    "spreads = spreads[spreads['schedule_season']>=2014]\n",
    "spreads = spreads[['schedule_season','schedule_week','team_home_abb','score_home','score_away','away_team_abb','team_favorite_id','spread_favorite','over_under_line','starting_spread', 'Total Score Open',\n",
    "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement','ou_movement', 'strong_movement', 'fav_team_stronger']]\n",
    "spreads['team_home_abb'] = spreads['team_home_abb'].astype(str)\n",
    "spreads['team_favorite_id'] = spreads['team_favorite_id'].astype(str)\n",
    "spreads['over_under_line'] = spreads['over_under_line'].astype(float)\n",
    "\n",
    "\n",
    "def fav_spread(nData):\n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:\n",
    "        return nData['spread_favorite']\n",
    "    else:\n",
    "        pass\n",
    "spreads['fav_spread'] = spreads.apply(lambda nData: fav_spread(nData), axis=1)\n",
    "\n",
    "def nonfav_spread(nData):\n",
    "    if nData['team_home_abb'] != nData['team_favorite_id']:\n",
    "        return nData['team_home_abb']\n",
    "    elif nData['away_team_abb'] != nData['team_favorite_id']:\n",
    "        return nData['away_team_abb']\n",
    "    else:\n",
    "        pass\n",
    "spreads['team_notfav_id'] = spreads.apply(lambda nData: nonfav_spread(nData), axis=1)\n",
    "\n",
    "def cover_or_not(nData):    \n",
    "    if nData['team_home_abb'] == nData['team_favorite_id']:\n",
    "        if ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] > 0:\n",
    "            return 'Cover'\n",
    "        elif ((nData['score_home']-nData['score_away']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'       \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "    elif nData['away_team_abb'] == nData['team_favorite_id']:        \n",
    "        if ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] > 0:            \n",
    "            return 'Cover'        \n",
    "        elif ((nData['score_away']-nData['score_home']))+nData['spread_favorite'] == 0:            \n",
    "            return 'Push'        \n",
    "        else:            \n",
    "            return 'No Cover'\n",
    "spreads['fav_cover'] = spreads.apply(lambda nData: cover_or_not(nData), axis=1)\n",
    "\n",
    "def OU_or_not(nData):    \n",
    "    if (nData['score_home']+nData['score_away']) > nData['over_under_line']:        \n",
    "        return 'Over'    \n",
    "    elif (nData['score_home']-nData['score_away']) == nData['over_under_line']:        \n",
    "        return 'Push'    \n",
    "    else:        \n",
    "        return 'Under'\n",
    "spreads['over_under_result'] = spreads.apply(lambda nData: OU_or_not(nData), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "spreads['schedule_season'] = spreads['schedule_season'].apply(int)    \n",
    "spreads['schedule_week'] = spreads['schedule_week'].apply(int)  \n",
    "data = spreads.sort_values(by=[\"team_home_abb\",\"schedule_season\",\"schedule_week\"], ascending=[True, True, True])\n",
    "\n",
    "def clean_spreads(df):\n",
    "    ##  basic scrubbing to clean data ##    \n",
    "    df['schedule_season'] = df['schedule_season'].apply(str)    \n",
    "    df['schedule_week'] = df['schedule_week'].apply(str)        \n",
    "    df=df.apply(lambda x: x.astype(str).str.lower())    \n",
    "    #df['schedule_week']=df['schedule_week'].astype(str).str[:-2].astype(object)    \n",
    "    #df['schedule_season'] = df['schedule_season'].astype(str).str[:-2].astype(object)  \n",
    "    df['team_home_abb'] = df['team_home_abb'].map(new_acc).fillna(df['team_home_abb'])\n",
    "    df['away_team_abb'] = df['away_team_abb'].map(new_acc).fillna(df['away_team_abb'])\n",
    "    \n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"home_matchup_id\", (df['team_home_abb']+'vs'+df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(1, \"away_matchup_id\", (df['away_team_abb']+'@'+df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(2, \"home_id\", (df['team_home_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    df.insert(3, \"away_id\", (df['away_team_abb']+'_'+df['schedule_season']+'_'+df['schedule_week']))\n",
    "    return df\n",
    "    \n",
    "data = clean_spreads(data)\n",
    "\n",
    "data = pd.merge(data, weather, on='away_matchup_id', how='left')\n",
    "\n",
    "\n",
    "sh = data\n",
    "sa = data\n",
    "\n",
    "sh = sh.rename(columns={'home_id':'team_id'})\n",
    "sh.drop('away_id', axis=1, inplace=True)\n",
    "\n",
    "sa = sa.rename(columns={'away_id':'team_id'})\n",
    "sa.drop('home_id', axis=1, inplace=True)\n",
    "\n",
    "spread_comb = pd.concat([sh, sa], axis=0)\n",
    "spread_comb['team_abb'] = spread_comb['team_id'].astype(str).str[:3]\n",
    "spread_comb['team_abb'] = spread_comb['team_abb'].str.replace(\"_\",\"\")\n",
    "\n",
    "def hora1(nData):\n",
    "    if nData['team_favorite_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    elif nData['team_notfav_id'] == nData['team_home_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['homeoraway'] = spread_comb.apply(lambda nData: hora1(nData), axis=1)\n",
    "\n",
    "def hora(nData):\n",
    "    if nData['team_favorite_id'] == nData['away_team_abb']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "spread_comb['fav_homeoraway'] = spread_comb.apply(lambda nData: hora(nData), axis=1)\n",
    "#sh['fav_homeoraway'] = sh.apply(lambda nData: hora(nData), axis=1)\n",
    "\n",
    "def ws(nData):\n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ls(nData):    \n",
    "    if (nData['fav_homeoraway'] == 0) & (nData['fav_cover'] == 'no cover'):\n",
    "        return 1\n",
    "    elif (nData['fav_homeoraway'] == 1) & (nData['fav_cover'] == 'cover'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "spread_comb['ats_w'] = spread_comb.apply(lambda nData: ws(nData), axis=1)\n",
    "spread_comb['ats_l'] = spread_comb.apply(lambda nData: ls(nData), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_matchup_id', 'away_matchup_id', 'team_id', 'schedule_season',\n",
       "       'schedule_week', 'team_home_abb', 'score_home', 'score_away',\n",
       "       'away_team_abb', 'team_favorite_id', 'spread_favorite',\n",
       "       'over_under_line', 'starting_spread', 'Total Score Open',\n",
       "       'fav_team_open', 'fav_team_cur', 'remain_fav', 'spread_movement',\n",
       "       'ou_movement', 'strong_movement', 'fav_team_stronger', 'fav_spread',\n",
       "       'team_notfav_id', 'fav_cover', 'over_under_result', 'precip', 'dome',\n",
       "       'temperature', 'wind_mph', 'team_abb', 'homeoraway', 'fav_homeoraway',\n",
       "       'ats_w', 'ats_l'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spread_comb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Football Outsiders rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rolling_fo(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    #data=data.fillna(data.mean())\n",
    "    num_cols = ['total_dvoa', 'off_dvoa','off_pass_dvoa', 'off_rush_dvoa', 'def_dvoa', 'def_pass_dvoa','def_rush_dvoa', 'special_teams_dvoa']\n",
    "    ids = data[['team_id', 'year', 'team', 'week', 'opp']].reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(['team','year'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in historic weekly football outsiders data and create the current week rows for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team_id</th>\n",
       "      <td>sea_2022_8</td>\n",
       "      <td>sf_2022_8</td>\n",
       "      <td>tb_2022_8</td>\n",
       "      <td>ten_2022_8</td>\n",
       "      <td>was_2022_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>sea</td>\n",
       "      <td>sf</td>\n",
       "      <td>tb</td>\n",
       "      <td>ten</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           218        219        220         221         222\n",
       "team_id             sea_2022_8  sf_2022_8  tb_2022_8  ten_2022_8  was_2022_8\n",
       "year                      2022       2022       2022        2022        2022\n",
       "team                       sea         sf         tb         ten         was\n",
       "week                         8          8          8           8           8\n",
       "opp                        NaN        NaN        NaN         NaN         NaN\n",
       "total_dvoa                 NaN        NaN        NaN         NaN         NaN\n",
       "off_dvoa                   NaN        NaN        NaN         NaN         NaN\n",
       "off_pass_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "off_rush_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "def_dvoa                   NaN        NaN        NaN         NaN         NaN\n",
       "def_pass_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "def_rush_dvoa              NaN        NaN        NaN         NaN         NaN\n",
       "special_teams_dvoa         NaN        NaN        NaN         NaN         NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t##Create the current weeks fo team_ids/rows to roll into##\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "fo_data_new = fo_data[~fo_data['week'].isnull()]\n",
    "fo_data_new=fo_data_new.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "fo_data_new['team_id']=fo_data_new['team_id'].str.replace(\"2022_\"+str(cur_week_int-1), str(\"2022_\"+cur_week_str))\n",
    "\n",
    "fo_data_new = fo_data_new.sort_values(by=[\"team\",\"week\"], ascending=[True, False])\n",
    "fo_data_new[fo_data_new.columns[4:]] = np.nan\n",
    "fo_data_new.tail().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in the historic FO data and concat all of them together for our rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_team_id</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>ari_2014_2</td>\n",
       "      <td>ari_2014_3</td>\n",
       "      <td>ari_2014_5</td>\n",
       "      <td>ari_2014_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "      <td>ari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opp</th>\n",
       "      <td>lac</td>\n",
       "      <td>nyg</td>\n",
       "      <td>sf</td>\n",
       "      <td>den</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.8</td>\n",
       "      <td>21.65</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>-2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_pass_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.05</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-14.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def_rush_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51.3</td>\n",
       "      <td>41.45</td>\n",
       "      <td>31.866667</td>\n",
       "      <td>18.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_teams_dvoa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.636667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1           2           3           4\n",
       "unique_team_id      ari_2014_1  ari_2014_2  ari_2014_3  ari_2014_5  ari_2014_6\n",
       "year                      2014        2014        2014        2014        2014\n",
       "team                       ari         ari         ari         ari         ari\n",
       "week                         1           2           3           5           6\n",
       "opp                        lac         nyg          sf         den         was\n",
       "total_dvoa                 NaN        0.59       0.625    0.613333        0.56\n",
       "off_dvoa                   NaN        0.53       0.505        0.55    0.533333\n",
       "off_pass_dvoa              NaN        0.53        0.45    0.516667    0.486667\n",
       "off_rush_dvoa              NaN        0.51        0.57        0.55        0.56\n",
       "def_dvoa                   NaN        29.8       21.65   10.433333        -2.8\n",
       "def_pass_dvoa              NaN        14.2        8.05        -1.8  -14.066667\n",
       "def_rush_dvoa              NaN        51.3       41.45   31.866667   18.866667\n",
       "special_teams_dvoa         NaN        0.35        0.61        0.61    0.636667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo_data_2022 = pd.read_csv(\"./historic_data/fo_data/fo_weekly_hist.csv\")\n",
    "fo_data = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/fo_weekly_update.csv\")\n",
    "\n",
    "fo = pd.concat([fo_data_2022, fo_data, fo_data_new], axis=0).reset_index(drop=True)\n",
    "\n",
    "fo['team'] = fo['team'].map(new_acc).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(new_acc).fillna(fo['opp']) \n",
    "\n",
    "fo['team'] = fo['team'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['team'])\n",
    "fo['opp'] = fo['opp'].map(utils.cleaning_dicts.clean_team_fo).fillna(fo['opp'])\n",
    "\n",
    "##combine our current season fo data with the new week 4 rows we just made##\n",
    "fo_roll = rolling_fo(data=fo, roll_value=3, roll_type='mean')\n",
    "fo_roll = fo_roll.rename(columns={'team_id': 'unique_team_id'})\n",
    "\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('sd_','lac_')\n",
    "fo_roll['unique_team_id']=fo_roll['unique_team_id'].str.replace('oak_','lv_')\n",
    "#fo_roll.drop(['year','team','week','opp'], axis=1, inplace=True)\n",
    "\n",
    "fo_roll.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PFF team_game_summaries (tgs) clean and create current week rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_new_week = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "\n",
    "tgs_new_week = tgs_new_week[~tgs_new_week['week'].isnull()]\n",
    "tgs_new_week=tgs_new_week.drop_duplicates(subset=['team','year'], keep='last').assign(week=cur_week_str)\n",
    "\n",
    "tgs_new_week['team_name'] = tgs_new_week['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs_new_week['team'])\n",
    "tgs_new_week['opponent_name'] = tgs_new_week['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs_new_week['opponent'])\n",
    "\n",
    "tgs_new_week['home_or_away']=tgs_new_week['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs_new_week['home_team'] = tgs_new_week.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs_new_week['away_team'] = tgs_new_week.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "tgs_new_week = clean_pff_team_summ(tgs_new_week)\n",
    "tgs_new_week['wl_int'] = ''\n",
    "tgs_new_week = tgs_new_week.sort_values(by=[\"team_name\",\"week\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now read in historic tgs data and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs_data_2022 = pd.read_csv(\"./historic_data/pff_data/team_game_summaries_historic.csv\")\n",
    "tgs_data_cur = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/team_game_summaries_w\"+cur_week_str+\".csv\")\n",
    "tgs = pd.concat([tgs_data_2022, tgs_data_cur], axis=0)\n",
    "\n",
    "tgs = tgs[tgs['year'] >= 2014]\n",
    "\n",
    "\n",
    "tgs['team_name'] = tgs['team'].map(utils.cleaning_dicts.clean_team_pff_full).fillna(tgs['team'])\n",
    "tgs['opponent_name'] = tgs['opponent'].map(utils.cleaning_dicts.clean_team_pff_opp).fillna(tgs['opponent'])\n",
    "\n",
    "##adding just incase accronyms have changed\n",
    "tgs['team_name'] = tgs['team_name'].map(new_acc).fillna(tgs['team_name'])\n",
    "tgs['opponent_name'] = tgs['opponent_name'].map(new_acc).fillna(tgs['opponent_name']) \n",
    "\n",
    "tgs['home_or_away']=tgs['home_or_away'].astype(str)\n",
    "\n",
    "def home_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['opponent_name']\n",
    "    else:\n",
    "        return nData['team_name']\n",
    "\n",
    "tgs['home_team'] = tgs.apply(lambda nData: home_team(nData), axis=1)\n",
    "\n",
    "def away_team(nData):\n",
    "    if str('@') in nData['home_or_away']:\n",
    "        return nData['team_name']\n",
    "    else:\n",
    "        return nData['opponent_name']\n",
    "    \n",
    "tgs['away_team'] = tgs.apply(lambda nData: away_team(nData), axis=1)\n",
    "\n",
    "def clean_pff_team_summ(df):\n",
    "##  basic scrubbing to clean data ##\n",
    "\n",
    "    df['year'] = df['year'].astype(str)\n",
    "    df['week'] = df['week'].astype(str)\n",
    "    df['home_or_away']=np.where(df['home_or_away'] == \"@\", 1, 0)\n",
    "    df['wl_int'] = np.where(df['wl'] == \"W\", 1, 0)\n",
    "    df=df.replace('-','', regex=True)\n",
    "    df=df.replace(' ','', regex=True)\n",
    "    \n",
    "    df['team_name'] = df['team_name'].map(new_acc).fillna(df['team_name'])\n",
    "    df['opponent_name'] = df['opponent_name'].map(new_acc).fillna(df['opponent_name'])\n",
    "\n",
    "\n",
    "    ##  create our unique ids  ##\n",
    "    df.insert(0, \"unique_team_id\", (df['team_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(1, \"team_id_impute\", (df['team_name']+'_'+df['year']))\n",
    "    df.insert(2, \"opponent_id\", (df['opponent_name']+'_'+df['year']+'_'+df['week']))\n",
    "    df.insert(3, \"home_matchup_id\", (df['home_team']+'vs'+df['away_team']+'_'+df['year']+'_'+df['week']))\n",
    "    \n",
    "    ##Impute missing special teams data added after 2014##\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_name'])[num_cols].fillna(df.mean()).reset_index(level=0, drop=True)\n",
    "   \n",
    "    return df\n",
    "\n",
    "\n",
    "   \n",
    "tgs_clean = clean_pff_team_summ(tgs)\n",
    "\n",
    "\n",
    "tgs_clean = pd.concat([tgs_clean, tgs_new_week], axis=0).reset_index(drop=True)\n",
    "tgs_clean['year']=tgs_clean['year'].apply(int)\n",
    "tgs_clean['week']=tgs_clean['week'].apply(int)\n",
    "tgs_clean['special_teams']=tgs_clean['special_teams'].apply(float)\n",
    "tgs_clean = tgs_clean.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "\n",
    "tgs_clean = tgs_clean[['unique_team_id','team_id_impute', 'home_matchup_id','opponent_id','wl','pf','pa','team_name','opponent_name','year','week','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>home_matchup_id</th>\n",
       "      <th>opponent_id</th>\n",
       "      <th>wl</th>\n",
       "      <th>pf</th>\n",
       "      <th>pa</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opponent_name</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>pass_blocking</th>\n",
       "      <th>receiving</th>\n",
       "      <th>rushing</th>\n",
       "      <th>run_blocking</th>\n",
       "      <th>defense</th>\n",
       "      <th>rush_defense</th>\n",
       "      <th>tackling</th>\n",
       "      <th>pass_rush</th>\n",
       "      <th>coverage</th>\n",
       "      <th>special_teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>was_2022_4</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>dalvswas_2022_4</td>\n",
       "      <td>dal_2022_4</td>\n",
       "      <td>L</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>was</td>\n",
       "      <td>dal</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>60.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>70.3</td>\n",
       "      <td>72.9</td>\n",
       "      <td>71.9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.8</td>\n",
       "      <td>66.8</td>\n",
       "      <td>68.1</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>was_2022_5</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsten_2022_5</td>\n",
       "      <td>ten_2022_5</td>\n",
       "      <td>L</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>ten</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>52.9</td>\n",
       "      <td>67.8</td>\n",
       "      <td>61.4</td>\n",
       "      <td>42.9</td>\n",
       "      <td>67.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>70.7</td>\n",
       "      <td>74.2</td>\n",
       "      <td>64.6</td>\n",
       "      <td>43.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>was_2022_6</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>chivswas_2022_6</td>\n",
       "      <td>chi_2022_6</td>\n",
       "      <td>W</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>was</td>\n",
       "      <td>chi</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>75.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>60.4</td>\n",
       "      <td>72.1</td>\n",
       "      <td>72.1</td>\n",
       "      <td>48.4</td>\n",
       "      <td>39.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>71.9</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>was_2022_7</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsgb_2022_7</td>\n",
       "      <td>gb_2022_7</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>gb</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>65.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375</th>\n",
       "      <td>was_2022_8</td>\n",
       "      <td>was_2022</td>\n",
       "      <td>wasvsgb_2022_8</td>\n",
       "      <td>gb_2022_8</td>\n",
       "      <td>W</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>was</td>\n",
       "      <td>gb</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>42.1</td>\n",
       "      <td>71.7</td>\n",
       "      <td>65.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_team_id team_id_impute  home_matchup_id opponent_id wl  pf  pa  \\\n",
       "4340     was_2022_4       was_2022  dalvswas_2022_4  dal_2022_4  L  10  25   \n",
       "4341     was_2022_5       was_2022  wasvsten_2022_5  ten_2022_5  L  17  21   \n",
       "4342     was_2022_6       was_2022  chivswas_2022_6  chi_2022_6  W  12   7   \n",
       "4343     was_2022_7       was_2022   wasvsgb_2022_7   gb_2022_7  W  23  21   \n",
       "4375     was_2022_8       was_2022   wasvsgb_2022_8   gb_2022_8  W  23  21   \n",
       "\n",
       "     team_name opponent_name  year  ...  pass_blocking  receiving  rushing  \\\n",
       "4340       was           dal  2022  ...           60.3       63.1     70.3   \n",
       "4341       was           ten  2022  ...           52.9       67.8     61.4   \n",
       "4342       was           chi  2022  ...           75.6       49.9     60.4   \n",
       "4343       was            gb  2022  ...           42.1       71.7     65.6   \n",
       "4375       was            gb  2022  ...           42.1       71.7     65.6   \n",
       "\n",
       "      run_blocking  defense  rush_defense  tackling  pass_rush  coverage  \\\n",
       "4340          72.9     71.9          72.0      68.8       66.8      68.1   \n",
       "4341          42.9     67.0          64.3      70.7       74.2      64.6   \n",
       "4342          72.1     72.1          48.4      39.6       88.6      71.9   \n",
       "4343          50.0     59.0          71.9      55.0       53.8      59.0   \n",
       "4375          50.0     59.0          71.9      55.0       53.8      59.0   \n",
       "\n",
       "      special_teams  \n",
       "4340           79.9  \n",
       "4341           43.9  \n",
       "4342           84.9  \n",
       "4343           66.9  \n",
       "4375           66.9  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_clean.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tgs rolling mean function and combine all tgs datasets together and pass through the rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_tgs(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"team_name\",\"year\",\"week\"], ascending=[True, True, True])\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        roll3 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data['team_id_impute'])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "        \n",
    "tgs_roll = rolling_tgs(data=tgs_clean, roll_value=3, roll_type='mean')\n",
    "\n",
    "tgs_roll = tgs_roll[['unique_team_id','wl','pf','pa','overall_performance', 'offense', 'pass',\n",
    "       'pass_blocking', 'receiving', 'rushing', 'run_blocking', 'defense',\n",
    "       'rush_defense', 'tackling', 'pass_rush', 'coverage', 'special_teams']]\n",
    "\n",
    "tgs_roll = tgs_roll.rename(columns={c: c+'_tgs' for c in tgs_roll.columns if c not in ['unique_team_id','wl','pf','pa']})\n",
    "\n",
    "tgs_roll.rename(columns={'unique_team_id_tgs_pff':'unique_team_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in all the pff current week datasets and prep for rolling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth_new = pd.read_csv(\"./current_data/week_\"+cur_week_str+\"/passing_depth_new_pp_w\"+cur_week_str+\".csv\")\n",
    "passing_allowed_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_allowed_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_pressure_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_pressure_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_concept_new_pp_w'+cur_week_str+\".csv\")\n",
    "time_in_pocket_new = pd.read_csv('./current_data/week_'+cur_week_str+'/time_in_pocket_new_pp_w'+cur_week_str+\".csv\")\n",
    "passing_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/passing_summ_conc_new_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "rec_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rec_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_concept_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_concept_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_depth_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_depth_pp_w'+cur_week_str+\".csv\")\n",
    "receiving_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/receiving_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "rush_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/rush_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "block_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/block_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "offense_pass_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_pass_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "offense_run_blocking_new = pd.read_csv('./current_data/week_'+cur_week_str+'/offense_run_blocking_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "def_summ_conc_new = pd.read_csv('./current_data/week_'+cur_week_str+'/def_summ_conc_pp_w'+cur_week_str+\".csv\")\n",
    "pass_rush_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/pass_rush_summary_pp_w'+cur_week_str+\".csv\")\n",
    "run_defense_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/run_defense_summary_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_scheme_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_scheme_pp_w'+cur_week_str+\".csv\")\n",
    "defense_coverage_summary_new = pd.read_csv('./current_data/week_'+cur_week_str+'/defense_coverage_summary_pp_w'+cur_week_str+\".csv\")\n",
    "slot_coverage_new = pd.read_csv('./current_data/week_'+cur_week_str+'/slot_coverage_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "st_kickers_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_kickers_pp_w'+cur_week_str+\".csv\")\n",
    "st_punters_new = pd.read_csv('./current_data/week_'+cur_week_str+'/st_punters_no_inj_pp_w'+cur_week_str+\".csv\")\n",
    "\n",
    "\n",
    "passing_depth_new['week'] = cur_week_str \n",
    "passing_allowed_pressure_new['week'] = cur_week_str \n",
    "passing_pressure_new['week'] = cur_week_str \n",
    "passing_concept_new['week'] = cur_week_str \n",
    "time_in_pocket_new['week'] = cur_week_str \n",
    "passing_summ_conc_new['week'] = cur_week_str \n",
    "rec_summ_conc_new['week'] = cur_week_str \n",
    "receiving_concept_new['week'] = cur_week_str\n",
    "receiving_depth_new['week'] = cur_week_str \n",
    "receiving_scheme_new['week'] = cur_week_str \n",
    "rush_summ_conc_new['week'] = cur_week_str\n",
    "block_summ_conc_new['week'] = cur_week_str \n",
    "offense_pass_blocking_new['week'] = cur_week_str \n",
    "offense_run_blocking_new['week'] = cur_week_str \n",
    "def_summ_conc_new['week'] = cur_week_str \n",
    "pass_rush_summary_new['week'] = cur_week_str \n",
    "run_defense_summary_new['week'] = cur_week_str \n",
    "defense_coverage_scheme_new['week'] = cur_week_str \n",
    "defense_coverage_summary_new['week'] = cur_week_str \n",
    "slot_coverage_new['week'] = cur_week_str \n",
    "st_kickers_new['week'] = cur_week_str \n",
    "st_punters_new['week'] = cur_week_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>player</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>player_game_count</th>\n",
       "      <th>assists</th>\n",
       "      <th>...</th>\n",
       "      <th>tackles</th>\n",
       "      <th>targets</th>\n",
       "      <th>total_pressures</th>\n",
       "      <th>touchdowns</th>\n",
       "      <th>yards</th>\n",
       "      <th>yards_after_catch</th>\n",
       "      <th>yards_per_reception</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>plyr_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>perrionwinfrey_cle_2022_8</td>\n",
       "      <td>cle_2022_8</td>\n",
       "      <td>perrionwinfrey_cle_2022</td>\n",
       "      <td>cle_2022</td>\n",
       "      <td>perrionwinfrey</td>\n",
       "      <td>122952</td>\n",
       "      <td>di</td>\n",
       "      <td>cle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>jaylenwatson_kc_2022_8</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>samroberts_ne_2022_8</td>\n",
       "      <td>ne_2022_8</td>\n",
       "      <td>samroberts_ne_2022</td>\n",
       "      <td>ne_2022</td>\n",
       "      <td>samroberts</td>\n",
       "      <td>156069</td>\n",
       "      <td>di</td>\n",
       "      <td>ne</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>joshuawilliams_kc_2022_8</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>christianmatthew_ari_2022_8</td>\n",
       "      <td>ari_2022_8</td>\n",
       "      <td>christianmatthew_ari_2022</td>\n",
       "      <td>ari_2022</td>\n",
       "      <td>christianmatthew</td>\n",
       "      <td>156140</td>\n",
       "      <td>cb</td>\n",
       "      <td>ari</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p_id unique_team_id             player_team_id  \\\n",
       "647    perrionwinfrey_cle_2022_8     cle_2022_8    perrionwinfrey_cle_2022   \n",
       "648       jaylenwatson_kc_2022_8      kc_2022_8       jaylenwatson_kc_2022   \n",
       "649         samroberts_ne_2022_8      ne_2022_8         samroberts_ne_2022   \n",
       "650     joshuawilliams_kc_2022_8      kc_2022_8     joshuawilliams_kc_2022   \n",
       "651  christianmatthew_ari_2022_8     ari_2022_8  christianmatthew_ari_2022   \n",
       "\n",
       "    team_id_impute            player  numeric_id position team_name  \\\n",
       "647       cle_2022    perrionwinfrey      122952       di       cle   \n",
       "648        kc_2022      jaylenwatson      131960       cb        kc   \n",
       "649        ne_2022        samroberts      156069       di        ne   \n",
       "650        kc_2022    joshuawilliams      156083       cb        kc   \n",
       "651       ari_2022  christianmatthew      156140       cb       ari   \n",
       "\n",
       "     player_game_count  assists  ...  tackles  targets  total_pressures  \\\n",
       "647                  1        0  ...        0        0                0   \n",
       "648                  1        3  ...        0        0                0   \n",
       "649                  1        0  ...        0        0                0   \n",
       "650                  1        1  ...        0        0                0   \n",
       "651                  1        0  ...        0        0                0   \n",
       "\n",
       "     touchdowns  yards  yards_after_catch  yards_per_reception  week  year  \\\n",
       "647           0      0                  0                    0     8  2022   \n",
       "648           0      0                  0                    0     8  2022   \n",
       "649           0      0                  0                    0     8  2022   \n",
       "650           0      0                  0                    0     8  2022   \n",
       "651           0      0                  0                    0     8  2022   \n",
       "\n",
       "     plyr_number  \n",
       "647            8  \n",
       "648            8  \n",
       "649            8  \n",
       "650            8  \n",
       "651            8  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the prefixes like we did for the pff datasets above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "\t\t\t\t\t\t\t\t###   add prefixes ###\n",
    "####################################################################################\t\n",
    "\n",
    "def create_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player_team_id','unique_team_id','team_id_impute','player','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','player','team_id_impute','numeric_id','position','team_name','unique_team_id','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "def id_prefix(prefix=None, df=None):\n",
    "    id = df[['p_id','player','player_team_id','unique_team_id','team_id_impute','numeric_id','position','team_name','year','week']]\n",
    "    temp = df.drop(['p_id','player','player_team_id','unique_team_id','plyr_number','team_id_impute','numeric_id','position','team_name','year','week','plyr_number'], axis=1)\n",
    "    temp = temp.add_prefix(prefix)\n",
    "    id = pd.concat([id, temp], axis=1)\n",
    "    return id\n",
    "\n",
    "passing_summ_conc_new = id_prefix(prefix=\"pass_summary_\", df=passing_summ_conc_new)\n",
    "rush_summ_conc_new  = id_prefix(prefix=\"rush_summary_\", df=rush_summ_conc_new)\n",
    "rec_summ_conc_new  = id_prefix(prefix=\"rec_summary_\", df=rec_summ_conc_new)\n",
    "block_summ_conc_new  = id_prefix(prefix=\"block_summary_\", df=block_summ_conc_new)\n",
    "def_summ_conc_new  = id_prefix(prefix=\"def_summary_\", df=def_summ_conc_new)\n",
    "st_kickers_new  = id_prefix(prefix=\"kicking_\", df=st_kickers_new)\n",
    "st_punters_new  = id_prefix(prefix=\"punting_\", df=st_punters_new)\n",
    "\n",
    "\n",
    "passing_depth_new = create_prefix(prefix=\"pass_depth_\", df=passing_depth_new)\n",
    "passing_allowed_pressure_new = create_prefix(prefix=\"pressure_source_\", df=passing_allowed_pressure_new)\n",
    "passing_pressure_new = create_prefix(prefix=\"pass_under_pressure_\", df=passing_pressure_new)\n",
    "passing_concept_new = create_prefix(prefix=\"pass_concept_\", df=passing_concept_new)\n",
    "time_in_pocket_new = create_prefix(prefix=\"pass_time_\", df=time_in_pocket_new)\n",
    "\n",
    "\n",
    "receiving_concept_new = create_prefix(prefix=\"rec_concept_\", df=receiving_concept_new)\n",
    "receiving_depth_new = create_prefix(prefix=\"rec_depth_\", df=receiving_depth_new)\n",
    "receiving_scheme_new = create_prefix(prefix=\"rec_scheme_\", df=receiving_scheme_new)\n",
    "\n",
    "offense_pass_blocking_new = create_prefix(prefix=\"pass_block_\", df=offense_pass_blocking_new)\n",
    "offense_run_blocking_new = create_prefix(prefix=\"run_block_\", df=offense_run_blocking_new)\n",
    "\n",
    "\n",
    "pass_rush_summary_new = create_prefix(prefix=\"pass_rush_\", df=pass_rush_summary_new)\n",
    "run_defense_summary_new = create_prefix(prefix=\"run_defense_\", df=run_defense_summary_new)\n",
    "defense_coverage_scheme_new = create_prefix(prefix=\"def_coverage_scheme_\", df=defense_coverage_scheme_new)\n",
    "defense_coverage_summary_new = create_prefix(prefix=\"def_coverage_summary_\", df=defense_coverage_summary_new)\n",
    "slot_coverage_new= create_prefix(prefix=\"def_slot_coverage_\", df=slot_coverage_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>player</th>\n",
       "      <th>player_team_id</th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>team_id_impute</th>\n",
       "      <th>numeric_id</th>\n",
       "      <th>position</th>\n",
       "      <th>team_name</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense</th>\n",
       "      <th>def_summary_snap_counts_slot</th>\n",
       "      <th>def_summary_stops</th>\n",
       "      <th>def_summary_tackles</th>\n",
       "      <th>def_summary_targets</th>\n",
       "      <th>def_summary_total_pressures</th>\n",
       "      <th>def_summary_touchdowns</th>\n",
       "      <th>def_summary_yards</th>\n",
       "      <th>def_summary_yards_after_catch</th>\n",
       "      <th>def_summary_yards_per_reception</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>perrionwinfrey_cle_2022_8</td>\n",
       "      <td>perrionwinfrey</td>\n",
       "      <td>perrionwinfrey_cle_2022</td>\n",
       "      <td>cle_2022_8</td>\n",
       "      <td>cle_2022</td>\n",
       "      <td>122952</td>\n",
       "      <td>di</td>\n",
       "      <td>cle</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>jaylenwatson_kc_2022_8</td>\n",
       "      <td>jaylenwatson</td>\n",
       "      <td>jaylenwatson_kc_2022</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>131960</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>samroberts_ne_2022_8</td>\n",
       "      <td>samroberts</td>\n",
       "      <td>samroberts_ne_2022</td>\n",
       "      <td>ne_2022_8</td>\n",
       "      <td>ne_2022</td>\n",
       "      <td>156069</td>\n",
       "      <td>di</td>\n",
       "      <td>ne</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>joshuawilliams_kc_2022_8</td>\n",
       "      <td>joshuawilliams</td>\n",
       "      <td>joshuawilliams_kc_2022</td>\n",
       "      <td>kc_2022_8</td>\n",
       "      <td>kc_2022</td>\n",
       "      <td>156083</td>\n",
       "      <td>cb</td>\n",
       "      <td>kc</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>christianmatthew_ari_2022_8</td>\n",
       "      <td>christianmatthew</td>\n",
       "      <td>christianmatthew_ari_2022</td>\n",
       "      <td>ari_2022_8</td>\n",
       "      <td>ari_2022</td>\n",
       "      <td>156140</td>\n",
       "      <td>cb</td>\n",
       "      <td>ari</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            p_id            player             player_team_id  \\\n",
       "647    perrionwinfrey_cle_2022_8    perrionwinfrey    perrionwinfrey_cle_2022   \n",
       "648       jaylenwatson_kc_2022_8      jaylenwatson       jaylenwatson_kc_2022   \n",
       "649         samroberts_ne_2022_8        samroberts         samroberts_ne_2022   \n",
       "650     joshuawilliams_kc_2022_8    joshuawilliams     joshuawilliams_kc_2022   \n",
       "651  christianmatthew_ari_2022_8  christianmatthew  christianmatthew_ari_2022   \n",
       "\n",
       "    unique_team_id team_id_impute  numeric_id position team_name  year week  \\\n",
       "647     cle_2022_8       cle_2022      122952       di       cle  2022    8   \n",
       "648      kc_2022_8        kc_2022      131960       cb        kc  2022    8   \n",
       "649      ne_2022_8        ne_2022      156069       di        ne  2022    8   \n",
       "650      kc_2022_8        kc_2022      156083       cb        kc  2022    8   \n",
       "651     ari_2022_8       ari_2022      156140       cb       ari  2022    8   \n",
       "\n",
       "     ...  def_summary_snap_counts_run_defense  def_summary_snap_counts_slot  \\\n",
       "647  ...                                    0                             0   \n",
       "648  ...                                    0                             0   \n",
       "649  ...                                    0                             0   \n",
       "650  ...                                    0                             0   \n",
       "651  ...                                    0                             0   \n",
       "\n",
       "     def_summary_stops  def_summary_tackles  def_summary_targets  \\\n",
       "647                  0                    0                    0   \n",
       "648                  0                    0                    0   \n",
       "649                  0                    0                    0   \n",
       "650                  0                    0                    0   \n",
       "651                  0                    0                    0   \n",
       "\n",
       "     def_summary_total_pressures  def_summary_touchdowns  def_summary_yards  \\\n",
       "647                            0                       0                  0   \n",
       "648                            0                       0                  0   \n",
       "649                            0                       0                  0   \n",
       "650                            0                       0                  0   \n",
       "651                            0                       0                  0   \n",
       "\n",
       "     def_summary_yards_after_catch  def_summary_yards_per_reception  \n",
       "647                              0                                0  \n",
       "648                              0                                0  \n",
       "649                              0                                0  \n",
       "650                              0                                0  \n",
       "651                              0                                0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring the historic and new player pool data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_depth = pd.concat([passing_depth, passing_depth_new], axis=0)\n",
    "passing_allowed_pressure = pd.concat([passing_allowed_pressure, passing_allowed_pressure_new], axis=0)\n",
    "passing_pressure = pd.concat([passing_pressure, passing_pressure_new], axis=0)\n",
    "passing_concept = pd.concat([passing_concept, passing_concept_new], axis=0)\n",
    "time_in_pocket = pd.concat([time_in_pocket, time_in_pocket_new], axis=0)\n",
    "passing_summ_conc = pd.concat([passing_summ_conc, passing_summ_conc_new], axis=0)\n",
    "\n",
    "\n",
    "rec_summ_conc = pd.concat([rec_summ_conc, rec_summ_conc_new], axis=0)\n",
    "receiving_concept = pd.concat([receiving_concept, receiving_concept_new], axis=0)\n",
    "receiving_depth = pd.concat([receiving_depth, receiving_depth_new], axis=0)\n",
    "receiving_scheme = pd.concat([receiving_scheme, receiving_scheme_new], axis=0)\n",
    "\n",
    "rush_summ_conc = pd.concat([rush_summ_conc, rush_summ_conc_new], axis=0)\n",
    "\n",
    "block_summ_conc = pd.concat([block_summ_conc, block_summ_conc_new], axis=0)\n",
    "offense_pass_blocking = pd.concat([offense_pass_blocking, offense_pass_blocking_new], axis=0)\n",
    "offense_run_blocking = pd.concat([offense_run_blocking, offense_run_blocking_new], axis=0)\n",
    "\n",
    "def_summ_conc = pd.concat([def_summ_conc, def_summ_conc_new], axis=0)\n",
    "pass_rush_summary = pd.concat([pass_rush_summary, pass_rush_summary_new], axis=0)\n",
    "run_defense_summary = pd.concat([run_defense_summary, run_defense_summary_new], axis=0)\n",
    "defense_coverage_scheme = pd.concat([defense_coverage_scheme, defense_coverage_scheme_new], axis=0)\n",
    "defense_coverage_summary = pd.concat([defense_coverage_summary, defense_coverage_summary_new], axis=0)\n",
    "slot_coverage = pd.concat([slot_coverage, slot_coverage_new], axis=0)\n",
    "\n",
    "st_kickers = pd.concat([st_kickers, st_kickers_new], axis=0)\n",
    "st_punters = pd.concat([st_punters, st_punters_new], axis=0)\n",
    "\n",
    "\n",
    "### after the concat cell ###\n",
    "passing_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_allowed_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_pressure.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "time_in_pocket.drop_duplicates(subset='p_id', inplace=True)\n",
    "passing_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "\n",
    "rec_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_concept.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_depth.drop_duplicates(subset='p_id', inplace=True)\n",
    "receiving_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "rush_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "block_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_pass_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "offense_run_blocking.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "def_summ_conc.drop_duplicates(subset='p_id', inplace=True)\n",
    "pass_rush_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "run_defense_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_scheme.drop_duplicates(subset='p_id', inplace=True)\n",
    "defense_coverage_summary.drop_duplicates(subset='p_id', inplace=True)\n",
    "slot_coverage.drop_duplicates(subset='p_id', inplace=True)\n",
    "\n",
    "st_kickers.drop_duplicates(subset='p_id', inplace=True)\n",
    "st_punters.drop_duplicates(subset='p_id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rolling function and pass pff datasets through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'player'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mrolling\u001b[0;34m(data, roll_value, roll_type)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6242\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6244\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6242\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6244\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'player'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def rolling(data=None, roll_value=None, roll_type=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data: input pandas dataframe to be rolled\n",
    "        roll_value: input the number, default is three ## we will need to modify the function if we want more ##\n",
    "        roll_type: 'mean','std', or 'var' are the only options at the point\n",
    "        ## assign mean for a given team & year as opposed to the entire dataset\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.sort_values(by=[\"player\",\"team_name\",\"year\",\"week\"], ascending=[True, True, True, True])\n",
    "    data['week']=data['week'].apply(str)\n",
    "    data['year']=data['year'].apply(str)\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ids = pd.DataFrame(data.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "   \n",
    "    if roll_type == 'mean':\n",
    "        #roll5 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        #roll4 = data.groupby(data['player_id'])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll3 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value).mean())\n",
    "        roll2 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-1).mean())\n",
    "        roll1 = data.groupby(data[\"player_team_id\"])[num_cols].apply(lambda x : x.shift().rolling(roll_value-2).mean())\n",
    "        roll3 = pd.DataFrame(roll3.combine_first(roll2).combine_first(roll1)).reset_index(drop=True)\n",
    "        df = pd.concat([ids, roll3], axis=1)\n",
    "    return df\n",
    "   \n",
    "passing_depth_roll = rolling(data=passing_depth, roll_value=3, roll_type='mean')\n",
    "passing_allowed_pressure_roll = rolling(data=passing_allowed_pressure, roll_value=3, roll_type='mean')\n",
    "passing_pressure_roll = rolling(data=passing_pressure, roll_value=3, roll_type='mean')\n",
    "passing_concept_roll = rolling(data=passing_concept, roll_value=3, roll_type='mean')\n",
    "time_in_pocket_roll = rolling(data=time_in_pocket, roll_value=3, roll_type='mean')\n",
    "passing_summ_conc_roll = rolling(data=passing_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "\n",
    "rec_summ_conc_roll = rolling(data=rec_summ_conc, roll_value=3, roll_type='mean')\n",
    "receiving_concept_roll =rolling(data=receiving_concept, roll_value=3, roll_type='mean')\n",
    "receiving_depth_roll = rolling(data=receiving_depth, roll_value=3, roll_type='mean')\n",
    "receiving_scheme_roll = rolling(data=receiving_scheme, roll_value=3, roll_type='mean')\n",
    "\n",
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n",
    "\n",
    "block_summ_conc_roll = rolling(data=block_summ_conc, roll_value=3, roll_type='mean')\n",
    "offense_pass_blocking_roll = rolling(data=offense_pass_blocking, roll_value=3, roll_type='mean')\n",
    "offense_run_blocking_roll = rolling(data=offense_run_blocking, roll_value=3, roll_type='mean')\n",
    "\n",
    "def_summ_conc_roll = rolling(data=def_summ_conc, roll_value=3, roll_type='mean')\n",
    "pass_rush_summary_roll = rolling(data=pass_rush_summary, roll_value=3, roll_type='mean')\n",
    "run_defense_summary_roll = rolling(data=run_defense_summary, roll_value=3, roll_type='mean')\n",
    "defense_coverage_scheme_roll = rolling(data=defense_coverage_scheme, roll_value=3, roll_type='mean')\n",
    "defense_coverage_summary_roll = rolling(data=defense_coverage_summary, roll_value=3, roll_type='mean')\n",
    "slot_coverage_roll = rolling(data=slot_coverage, roll_value=3, roll_type='mean')\n",
    "\n",
    "st_kickers_roll = rolling(data=st_kickers, roll_value=3, roll_type='mean')\n",
    "st_punters_roll = rolling(data=st_punters, roll_value=3, roll_type='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll = rolling(data=rush_summ_conc, roll_value=3, roll_type='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Create better imputation function before weighting team_position_group functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter_fillna(df=None, position=None, min_Var=None):\n",
    "    sub= df[df['position'].str.match(position)]\n",
    "    sub_limit = sub[(sub[min_Var] <=5) & (sub[min_Var] >=1)]\n",
    "    buckup_df = pd.DataFrame(sub_limit.median()).T\n",
    "    num_cols = sub.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    msk = sub.isnull()\n",
    "    tmp = sub[num_cols].mask(msk, buckup_df[num_cols])\n",
    "    tmp = np.where(msk[num_cols], buckup_df[num_cols], tmp[num_cols])\n",
    "    tmp = pd.DataFrame(tmp, columns=buckup_df.columns)\n",
    "    ids = pd.DataFrame(sub.select_dtypes(exclude=[np.number])).reset_index(drop=True)\n",
    "    mrg = pd.concat([ids, tmp], axis=1)\n",
    "    return mrg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'team_id_impute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team_id_impute'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mimpute\u001b[0;34m(df)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cloak/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'team_id_impute'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def impute(df):\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    df[num_cols]= df.groupby(df['team_id_impute'])[num_cols].fillna(df.median()).reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "passing_depth_roll = impute(passing_depth_roll)\n",
    "passing_allowed_pressure_roll = impute(passing_allowed_pressure_roll)\n",
    "passing_pressure_roll = impute(passing_pressure_roll)\n",
    "passing_concept_roll = impute(passing_concept_roll)\n",
    "time_in_pocket_roll = impute(time_in_pocket_roll)\n",
    "passing_summ_conc_roll = impute(passing_summ_conc_roll)\n",
    "\n",
    "rec_summ_conc_roll = impute(rec_summ_conc_roll)\n",
    "receiving_concept_roll = impute(receiving_concept_roll)\n",
    "receiving_depth_roll = impute(receiving_depth_roll)\n",
    "receiving_scheme_roll = impute(receiving_scheme_roll)\n",
    "\n",
    "rush_summ_conc_roll = impute(rush_summ_conc_roll)\n",
    "\n",
    "block_summ_conc_roll = impute(block_summ_conc_roll)\n",
    "offense_pass_blocking_roll = impute(offense_pass_blocking_roll)\n",
    "offense_run_blocking_roll = impute(offense_run_blocking_roll)\n",
    "\n",
    "def_summ_conc_roll = impute(def_summ_conc_roll)\n",
    "pass_rush_summary_roll = impute(pass_rush_summary_roll)\n",
    "run_defense_summary_roll = impute(run_defense_summary_roll)\n",
    "defense_coverage_scheme_roll = impute(defense_coverage_scheme_roll)\n",
    "defense_coverage_summary_roll = impute(defense_coverage_summary_roll)\n",
    "slot_coverage_roll = impute(slot_coverage_roll)\n",
    "\n",
    "st_kickers_roll = impute(st_kickers_roll)\n",
    "st_punters_roll = impute(st_punters_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "biometrics = pd.read_csv('./other_data/2022_imputed_combine.csv')\n",
    "biometrics=biometrics[['player_team_id','position','height_clean','weight_clean', 'speed_clean',\n",
    "'hand_size', 'arm_length', 'bench','vertical', 'broad_jump', 'shuttle', '3cone', 'explosive', 'size_speed','draft_yr', 'round', 'selection']]\n",
    "biometrics['position']=biometrics['position'].apply(str)\n",
    "\n",
    "\n",
    "qb_bio = biometrics[biometrics['position'].isin(['qb'])]\n",
    "rb_bio = biometrics[biometrics['position'].isin(['rb','qb','fb','wr'])]\n",
    "rec_bio = biometrics[biometrics['position'].isin(['wr','te','rb'])]\n",
    "ol_bio = biometrics[biometrics['position'].isin(['ol','te'])]\n",
    "def_bio_dl = biometrics[biometrics['position'].isin(['dl'])]\n",
    "def_bio_db = biometrics[biometrics['position'].isin(['db'])]\n",
    "def_bio_lb = biometrics[biometrics['position'].isin(['lb'])]\n",
    "st_bio = biometrics[biometrics['position'].isin(['st'])]\n",
    "\n",
    "qb_median = qb_bio.groupby(['position']).median().reset_index()\n",
    "rb_median = rb_bio.groupby(['position']).median().reset_index()\n",
    "rec_median = rec_bio.groupby(['position']).median().reset_index()\n",
    "ol_median = ol_bio.groupby(['position']).median().reset_index()\n",
    "dl_median = def_bio_dl.groupby(['position']).median().reset_index()\n",
    "db_median = def_bio_db.groupby(['position']).median().reset_index()\n",
    "lb_median = def_bio_lb.groupby(['position']).median().reset_index()\n",
    "st_median = st_bio.groupby(['position']).median().reset_index()\n",
    "\n",
    "\n",
    "qb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rb_bio.drop(['position'], axis=1, inplace=True)\n",
    "rec_bio.drop(['position'], axis=1, inplace=True)\n",
    "ol_bio.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_dl.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_db.drop(['position'], axis=1, inplace=True)\n",
    "def_bio_lb.drop(['position'], axis=1, inplace=True)\n",
    "st_bio.drop(['position'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position ##\n",
    "rush_summ_conc_roll['position'] = rush_summ_conc_roll['position'].str.replace('fb','hb')\n",
    "temp_fillna_df = pd.merge(rush_summ_conc_roll, rb_median, on='position', how='left')\n",
    "rush_summ_conc_roll = pd.merge(rush_summ_conc_roll, rb_bio, on='player_team_id', how='left')\n",
    "rush_summ_conc_roll = rush_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- qb ##\n",
    "temp_fillna_df = pd.merge(passing_summ_conc_roll, qb_median, on='position', how='left')\n",
    "passing_summ_conc_roll = pd.merge(passing_summ_conc_roll, qb_bio, on='player_team_id', how='left')\n",
    "passing_summ_conc_roll = passing_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "temp_fillna_df = pd.merge(rec_summ_conc_roll, rec_median, on='position', how='left')\n",
    "rec_summ_conc_roll = pd.merge(rec_summ_conc_roll, rec_bio, on='player_team_id', how='left')\n",
    "rec_summ_conc_roll = rec_summ_conc_roll.combine_first(temp_fillna_df)\n",
    "\n",
    "## fill in missing bio data with median for position- rec ##\n",
    "temp_fillna_df = pd.merge(block_summ_conc_roll , ol_median, on='position', how='left')\n",
    "block_summ_conc_roll = pd.merge(block_summ_conc_roll, ol_bio, on='player_team_id', how='left')\n",
    "block_summ_conc_roll = block_summ_conc_roll.combine_first(temp_fillna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine players for each dataset into team_year_week groupings\n",
    "\n",
    "### These next few cells will compute weighted averages based on average snaps played.  The first function will default snaps to 1 if snap value is 0.  The rest of the functions are dataset specific and will compute the weighted averages based on rollup aaverages and snaps played.\n",
    "\n",
    "#### For example: Washington had 5 rbs player in the last 3 games.  It doesn't make sense to weight all the players stats into a single average if 3 of those backs only averaged 2 snaps and rushed for 2 yards whereas B. Robinson averages 18 snaps and rushes for 65 yards and Gibson averages 10 snaps for 40 yards.  Therefore we weight each players rolling average based on their rolling snaps played. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute rushing weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rush_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rush_summ_conc_roll['rush_summary_attempts'] = rush_summ_conc_roll.apply(lambda df: rush_att(df, var='rush_summary_attempts'), axis=1)   \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rush_summary_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "\n",
    "rb_stats = rush_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "rb_stats.tail(n=10)\n",
    "rb_stats = rb_stats.rename(columns={c: c+'_rush' for c in rb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_rush_rush</th>\n",
       "      <th>rush_summary_attempts_rush_rush</th>\n",
       "      <th>rush_summary_avoided_tackles_rush_rush</th>\n",
       "      <th>rush_summary_breakaway_attempts_rush_rush</th>\n",
       "      <th>rush_summary_breakaway_percent_rush_rush</th>\n",
       "      <th>rush_summary_breakaway_yards_rush_rush</th>\n",
       "      <th>rush_summary_declined_penalties_rush_rush</th>\n",
       "      <th>rush_summary_designed_yards_rush_rush</th>\n",
       "      <th>rush_summary_drops_rush_rush</th>\n",
       "      <th>...</th>\n",
       "      <th>bench_rush_rush</th>\n",
       "      <th>vertical_rush_rush</th>\n",
       "      <th>broad_jump_rush_rush</th>\n",
       "      <th>shuttle_rush_rush</th>\n",
       "      <th>3cone_rush_rush</th>\n",
       "      <th>explosive_rush_rush</th>\n",
       "      <th>size_speed_rush_rush</th>\n",
       "      <th>draft_yr_rush_rush</th>\n",
       "      <th>round_rush_rush</th>\n",
       "      <th>selection_rush_rush</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9443.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>7422.375000</td>\n",
       "      <td>17.173611</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>16.173611</td>\n",
       "      <td>13.694444</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>61.482639</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>7569.011364</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>16.286115</td>\n",
       "      <td>13.621212</td>\n",
       "      <td>0.026515</td>\n",
       "      <td>47.628788</td>\n",
       "      <td>0.486742</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>7464.839080</td>\n",
       "      <td>14.340996</td>\n",
       "      <td>1.750958</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17.778632</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.938697</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>7676.854839</td>\n",
       "      <td>12.505376</td>\n",
       "      <td>1.263441</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>10.233871</td>\n",
       "      <td>4.295699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.174731</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_rush_rush  rush_summary_attempts_rush_rush  \\\n",
       "0     ari_2014_1           9443.000000                         4.000000   \n",
       "1    ari_2014_10           7422.375000                        17.173611   \n",
       "2    ari_2014_11           7569.011364                        15.750000   \n",
       "3    ari_2014_12           7464.839080                        14.340996   \n",
       "4    ari_2014_13           7676.854839                        12.505376   \n",
       "\n",
       "   rush_summary_avoided_tackles_rush_rush  \\\n",
       "0                                0.666667   \n",
       "1                                0.958333   \n",
       "2                                0.886364   \n",
       "3                                1.750958   \n",
       "4                                1.263441   \n",
       "\n",
       "   rush_summary_breakaway_attempts_rush_rush  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.708333   \n",
       "2                                   0.704545   \n",
       "3                                   0.666667   \n",
       "4                                   0.252688   \n",
       "\n",
       "   rush_summary_breakaway_percent_rush_rush  \\\n",
       "0                                  0.000000   \n",
       "1                                 16.173611   \n",
       "2                                 16.286115   \n",
       "3                                 17.778632   \n",
       "4                                 10.233871   \n",
       "\n",
       "   rush_summary_breakaway_yards_rush_rush  \\\n",
       "0                                0.000000   \n",
       "1                               13.694444   \n",
       "2                               13.621212   \n",
       "3                               12.000000   \n",
       "4                                4.295699   \n",
       "\n",
       "   rush_summary_declined_penalties_rush_rush  \\\n",
       "0                                   0.000000   \n",
       "1                                   0.046875   \n",
       "2                                   0.026515   \n",
       "3                                   0.000000   \n",
       "4                                   0.000000   \n",
       "\n",
       "   rush_summary_designed_yards_rush_rush  rush_summary_drops_rush_rush  ...  \\\n",
       "0                              16.333333                      0.000000  ...   \n",
       "1                              61.482639                      0.708333  ...   \n",
       "2                              47.628788                      0.486742  ...   \n",
       "3                              38.938697                      0.011494  ...   \n",
       "4                              23.174731                      0.505376  ...   \n",
       "\n",
       "   bench_rush_rush  vertical_rush_rush  broad_jump_rush_rush  \\\n",
       "0              NaN                 NaN                   NaN   \n",
       "1              NaN                 NaN                   NaN   \n",
       "2              NaN                 NaN                   NaN   \n",
       "3              NaN                 NaN                   NaN   \n",
       "4              NaN                 NaN                   NaN   \n",
       "\n",
       "   shuttle_rush_rush  3cone_rush_rush  explosive_rush_rush  \\\n",
       "0                NaN              NaN                  NaN   \n",
       "1                NaN              NaN                  NaN   \n",
       "2                NaN              NaN                  NaN   \n",
       "3                NaN              NaN                  NaN   \n",
       "4                NaN              NaN                  NaN   \n",
       "\n",
       "   size_speed_rush_rush  draft_yr_rush_rush  round_rush_rush  \\\n",
       "0                   NaN                 NaN              NaN   \n",
       "1                   NaN                 NaN              NaN   \n",
       "2                   NaN                 NaN              NaN   \n",
       "3                   NaN                 NaN              NaN   \n",
       "4                   NaN                 NaN              NaN   \n",
       "\n",
       "   selection_rush_rush  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_stats = rb_stats.rename(columns={c: c+'_rush' for c in rb_stats.columns if c not in ['unique_team_id']}); rb_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Passing weight average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def pass_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "passing_summ_conc_roll['pass_summary_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_summary_dropbacks'), axis=1)\n",
    "passing_depth_roll['pass_depth_base_dropbacks'] = passing_depth_roll.apply(lambda df: pass_att(df, var='pass_depth_base_dropbacks'), axis=1)  \n",
    "passing_pressure_roll['pass_under_pressure_base_dropbacks'] = passing_pressure_roll.apply(lambda df: pass_att(df, var='pass_under_pressure_base_dropbacks'), axis=1)  \n",
    "passing_allowed_pressure_roll['pressure_source_allowed_pressure_dropbacks'] = passing_allowed_pressure_roll.apply(lambda df: pass_att(df, var='pressure_source_allowed_pressure_dropbacks'), axis=1)  \n",
    "#passing_concept_roll['pass_concept_dropbacks'] = passing_summ_conc_roll.apply(lambda df: pass_att(df, var='pass_concept_dropbacks'), axis=1)  \n",
    "time_in_pocket_roll['pass_time_dropbacks'] = time_in_pocket_roll.apply(lambda df: pass_att(df, var='pass_time_dropbacks'), axis=1)     \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='pass_summary_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "qb_stats = passing_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_depth_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "pass_depth_stats = passing_depth_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pressure_source_allowed_pressure_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_allowed_pressure_stats = passing_allowed_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_under_pressure_base_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_pressure_stats = passing_pressure_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_concept_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "passing_concept_stats = passing_concept_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_time_dropbacks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "time_in_pocke_stats = time_in_pocket_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "qb_stats = qb_stats.rename(columns={c: c+'_passing' for c in qb_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute receiver weighted average datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "## make sure we aren't weighting w/a 0 value (non-designed runs are cancelled ##\n",
    "def rec_att(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "rec_summ_conc_roll['rec_summary_targets'] = rec_summ_conc_roll.apply(lambda df: rec_att(df, var='rec_summary_targets'), axis=1)   \n",
    "receiving_concept_roll['rec_concept_base_targets'] = receiving_concept_roll.apply(lambda df: rec_att(df, var='rec_concept_base_targets'), axis=1) \n",
    "receiving_depth_roll['rec_depth_base_targets'] = receiving_depth_roll.apply(lambda df: rec_att(df, var='rec_depth_base_targets'), axis=1) \n",
    "receiving_scheme_roll['rec_scheme_base_targets'] = receiving_scheme_roll.apply(lambda df: rec_att(df, var='rec_scheme_base_targets'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='rec_summary_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\n",
    "rec_stats = rec_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_concept_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_concept = receiving_concept.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_depth_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_depth = receiving_depth.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='rec_scheme_base_targets'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "receiving_scheme = receiving_scheme.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "rec_stats = rec_stats.rename(columns={c: c+'_rec' for c in rec_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute OL weighted average dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def snap_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "block_summ_conc_roll['block_summary_snap_counts_offense'] = block_summ_conc_roll.apply(lambda df: snap_fix(df, var='block_summary_snap_counts_offense'), axis=1)\n",
    "offense_pass_blocking_roll['pass_block_snap_counts_pass_block'] = offense_pass_blocking_roll.apply(lambda df: snap_fix(df, var='pass_block_snap_counts_pass_block'), axis=1) \n",
    "offense_run_blocking_roll['run_block_snap_counts_run_block'] = offense_run_blocking_roll.apply(lambda df: snap_fix(df, var='run_block_snap_counts_run_block'), axis=1) \n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='block_summary_snap_counts_offense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "ol_stats = block_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='pass_block_snap_counts_pass_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_pass_blocking_roll = offense_pass_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "def weighted(nData, snap_Var='run_block_snap_counts_run_block'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "offense_run_blocking_roll = offense_run_blocking_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "ol_stats = ol_stats.rename(columns={c: c+'_block' for c in ol_stats.columns if c not in ['unique_team_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "di    19496\n",
       "ed    17715\n",
       "cb    17152\n",
       "lb    15158\n",
       "s     14160\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_roll.position.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dl    5082\n",
       "db    4783\n",
       "ol    4748\n",
       "wr    3331\n",
       "hb    2658\n",
       "lb    2527\n",
       "te    1903\n",
       "qb    1294\n",
       "st     352\n",
       "Name: position, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometrics.position.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute defensive weighted averages datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_team_id</th>\n",
       "      <th>numeric_id_def_stats</th>\n",
       "      <th>def_summary_assists_def_stats</th>\n",
       "      <th>def_summary_batted_passes_def_stats</th>\n",
       "      <th>def_summary_catch_rate_def_stats</th>\n",
       "      <th>def_summary_declined_penalties_def_stats</th>\n",
       "      <th>def_summary_forced_fumbles_def_stats</th>\n",
       "      <th>def_summary_franchise_id_def_stats</th>\n",
       "      <th>def_summary_grades_coverage_defense_def_stats</th>\n",
       "      <th>def_summary_grades_defense_def_stats</th>\n",
       "      <th>...</th>\n",
       "      <th>def_summary_snap_counts_run_defense_def_stats</th>\n",
       "      <th>def_summary_snap_counts_slot_def_stats</th>\n",
       "      <th>def_summary_stops_def_stats</th>\n",
       "      <th>def_summary_tackles_def_stats</th>\n",
       "      <th>def_summary_targets_def_stats</th>\n",
       "      <th>def_summary_total_pressures_def_stats</th>\n",
       "      <th>def_summary_touchdowns_def_stats</th>\n",
       "      <th>def_summary_yards_def_stats</th>\n",
       "      <th>def_summary_yards_after_catch_def_stats</th>\n",
       "      <th>def_summary_yards_per_reception_def_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ari_2014_1</td>\n",
       "      <td>9074.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.226821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.584477</td>\n",
       "      <td>61.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>11.358518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ari_2014_10</td>\n",
       "      <td>5453.149401</td>\n",
       "      <td>0.380565</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>73.237718</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.770461</td>\n",
       "      <td>64.293564</td>\n",
       "      <td>...</td>\n",
       "      <td>16.002283</td>\n",
       "      <td>4.670234</td>\n",
       "      <td>1.309932</td>\n",
       "      <td>2.685502</td>\n",
       "      <td>2.461473</td>\n",
       "      <td>1.149258</td>\n",
       "      <td>0.061787</td>\n",
       "      <td>18.608019</td>\n",
       "      <td>8.409675</td>\n",
       "      <td>12.376737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ari_2014_11</td>\n",
       "      <td>5259.055969</td>\n",
       "      <td>0.356216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.635314</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.019968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.691524</td>\n",
       "      <td>64.336686</td>\n",
       "      <td>...</td>\n",
       "      <td>17.159160</td>\n",
       "      <td>6.133217</td>\n",
       "      <td>1.411602</td>\n",
       "      <td>2.897683</td>\n",
       "      <td>2.704999</td>\n",
       "      <td>1.277511</td>\n",
       "      <td>0.092552</td>\n",
       "      <td>20.999708</td>\n",
       "      <td>11.907739</td>\n",
       "      <td>12.039939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ari_2014_12</td>\n",
       "      <td>5376.940635</td>\n",
       "      <td>0.350820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.261585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030531</td>\n",
       "      <td>1.857766</td>\n",
       "      <td>63.717993</td>\n",
       "      <td>66.110585</td>\n",
       "      <td>...</td>\n",
       "      <td>16.160730</td>\n",
       "      <td>4.933366</td>\n",
       "      <td>1.549915</td>\n",
       "      <td>2.554963</td>\n",
       "      <td>2.191543</td>\n",
       "      <td>1.125596</td>\n",
       "      <td>0.050238</td>\n",
       "      <td>14.750303</td>\n",
       "      <td>9.143728</td>\n",
       "      <td>11.583611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ari_2014_13</td>\n",
       "      <td>5505.065511</td>\n",
       "      <td>0.474310</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>72.629271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>1.852601</td>\n",
       "      <td>62.197780</td>\n",
       "      <td>65.108462</td>\n",
       "      <td>...</td>\n",
       "      <td>16.156069</td>\n",
       "      <td>4.162974</td>\n",
       "      <td>1.693963</td>\n",
       "      <td>2.491169</td>\n",
       "      <td>1.885517</td>\n",
       "      <td>1.307001</td>\n",
       "      <td>0.048170</td>\n",
       "      <td>15.314547</td>\n",
       "      <td>10.003051</td>\n",
       "      <td>11.375241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_team_id  numeric_id_def_stats  def_summary_assists_def_stats  \\\n",
       "0     ari_2014_1           9074.000000                       0.333333   \n",
       "1    ari_2014_10           5453.149401                       0.380565   \n",
       "2    ari_2014_11           5259.055969                       0.356216   \n",
       "3    ari_2014_12           5376.940635                       0.350820   \n",
       "4    ari_2014_13           5505.065511                       0.474310   \n",
       "\n",
       "   def_summary_batted_passes_def_stats  def_summary_catch_rate_def_stats  \\\n",
       "0                             0.000000                         70.226821   \n",
       "1                             0.021261                         73.237718   \n",
       "2                             0.000000                         70.635314   \n",
       "3                             0.000000                         69.261585   \n",
       "4                             0.056840                         72.629271   \n",
       "\n",
       "   def_summary_declined_penalties_def_stats  \\\n",
       "0                                  0.000000   \n",
       "1                                  0.040382   \n",
       "2                                  0.022154   \n",
       "3                                  0.000000   \n",
       "4                                  0.000000   \n",
       "\n",
       "   def_summary_forced_fumbles_def_stats  def_summary_franchise_id_def_stats  \\\n",
       "0                              0.000000                           16.000000   \n",
       "1                              0.012700                            1.000000   \n",
       "2                              0.019968                            1.000000   \n",
       "3                              0.030531                            1.857766   \n",
       "4                              0.029383                            1.852601   \n",
       "\n",
       "   def_summary_grades_coverage_defense_def_stats  \\\n",
       "0                                      60.584477   \n",
       "1                                      63.770461   \n",
       "2                                      63.691524   \n",
       "3                                      63.717993   \n",
       "4                                      62.197780   \n",
       "\n",
       "   def_summary_grades_defense_def_stats  ...  \\\n",
       "0                             61.850000  ...   \n",
       "1                             64.293564  ...   \n",
       "2                             64.336686  ...   \n",
       "3                             66.110585  ...   \n",
       "4                             65.108462  ...   \n",
       "\n",
       "   def_summary_snap_counts_run_defense_def_stats  \\\n",
       "0                                      14.666667   \n",
       "1                                      16.002283   \n",
       "2                                      17.159160   \n",
       "3                                      16.160730   \n",
       "4                                      16.156069   \n",
       "\n",
       "   def_summary_snap_counts_slot_def_stats  def_summary_stops_def_stats  \\\n",
       "0                                0.666667                     1.000000   \n",
       "1                                4.670234                     1.309932   \n",
       "2                                6.133217                     1.411602   \n",
       "3                                4.933366                     1.549915   \n",
       "4                                4.162974                     1.693963   \n",
       "\n",
       "   def_summary_tackles_def_stats  def_summary_targets_def_stats  \\\n",
       "0                       2.000000                       0.666667   \n",
       "1                       2.685502                       2.461473   \n",
       "2                       2.897683                       2.704999   \n",
       "3                       2.554963                       2.191543   \n",
       "4                       2.491169                       1.885517   \n",
       "\n",
       "   def_summary_total_pressures_def_stats  def_summary_touchdowns_def_stats  \\\n",
       "0                               0.333333                          0.000000   \n",
       "1                               1.149258                          0.061787   \n",
       "2                               1.277511                          0.092552   \n",
       "3                               1.125596                          0.050238   \n",
       "4                               1.307001                          0.048170   \n",
       "\n",
       "   def_summary_yards_def_stats  def_summary_yards_after_catch_def_stats  \\\n",
       "0                     3.333333                                 1.333333   \n",
       "1                    18.608019                                 8.409675   \n",
       "2                    20.999708                                11.907739   \n",
       "3                    14.750303                                 9.143728   \n",
       "4                    15.314547                                10.003051   \n",
       "\n",
       "   def_summary_yards_per_reception_def_stats  \n",
       "0                                  11.358518  \n",
       "1                                  12.376737  \n",
       "2                                  12.039939  \n",
       "3                                  11.583611  \n",
       "4                                  11.375241  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_summ_conc_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def snap_fixs(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\n",
    "def_summ_conc_roll['def_summary_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_run_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_run_defense'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_pass_rush'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_pass_rush'), axis=1) \n",
    "def_summ_conc_roll['def_summary_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_summary_snap_counts_coverage'), axis=1) \n",
    "\n",
    "\n",
    "# pass_rush_summary_roll['pass_rush_snap_counts_pass_play'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='pass_rush_snap_counts_pass_play'), axis=1)\n",
    "# run_defense_summary_roll['run_defense_snap_counts_run'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='run_defense_snap_counts_run'), axis=1)\n",
    "# defense_coverage_scheme_roll['def_coverage_scheme_base_snap_counts_coverage'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_scheme_base_snap_counts_coverage'), axis=1)\n",
    "# defense_coverage_summary_roll['def_coverage_summary_coverage_snaps_per_target'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_coverage_summary_coverage_snaps_per_target'), axis=1)\n",
    "# slot_coverage_roll['def_slot_coverage_snap_counts_defense'] = def_summ_conc_roll.apply(lambda df: snap_fixs(df, var='def_slot_coverage_snap_counts_defense'), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Subset into defense positional groups ##\n",
    "def_rundef = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['ed','di','lb'])]\n",
    "def_passrush = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','ed','di'])]\n",
    "def_cov = def_summ_conc_roll[def_summ_conc_roll['position'].isin(['lb','cb','s'])]\n",
    "\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('di','dl')\n",
    "# def_rundef['position'] = def_rundef['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_rundef , dl_median, on='position', how='left')\n",
    "# def_rundef = pd.merge(def_rundef, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_rundef = def_rundef.combine_first(temp_fillna_df); def_rundef.head()\n",
    "\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('di','dl')\n",
    "# def_passrush['position'] = def_passrush['position'].str.replace('ed','dl')\n",
    "# temp_fillna_df = pd.merge(def_passrush , dl_median, on='position', how='left')\n",
    "# def_passrush = pd.merge(def_passrush, def_bio_dl, on='player_team_id', how='left')\n",
    "# def_passrush = def_passrush.combine_first(temp_fillna_df); def_passrush.head()\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_stats = def_summ_conc_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_stats = def_stats.rename(columns={c: c+'_def_stats' for c in def_stats.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_run_defense'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_rundef = def_rundef.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_rundef = def_rundef.rename(columns={c: c+'_run_def' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_pass_rush'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_passrush = def_passrush.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_passrush = def_passrush.rename(columns={c: c+'_passrush' for c in def_passrush.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "def weighted(nData, snap_Var='def_summary_snap_counts_coverage'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "def_cov = def_cov.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "def_cov = def_cov.rename(columns={c: c+'_def_cov' for c in def_cov.columns if c not in ['unique_team_id']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def weighted(nData, snap_Var='pass_rush_snap_counts_pass_play'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# pass_rush_stats = pass_rush_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='run_defense_snap_counts_run'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# run_defense_stats = run_defense_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_coverage_summary_coverage_snaps_per_target'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# defense_coverage_summary_stats = defense_coverage_summary_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_coverage_scheme_base_snap_counts_coverage'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# defense_coverage_scheme_stats = defense_coverage_scheme_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "# def weighted(nData, snap_Var='def_slot_coverage_snap_counts_defense'):\n",
    "#     data_cols = nData.select_dtypes(include=[np.number])\n",
    "#     num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "#     return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "# slot_coverage_stats = slot_coverage_roll.groupby('unique_team_id').apply(weighted).reset_index()\n",
    "\n",
    "#def_stats = pd.merge(def_stats, def_rundef, on='unique_team_id', how='inner').merge(def_passrush, on='unique_team_id', how='inner').merge(def_cov, on='unique_team_id', how='inner')\n",
    "# def_rundef = def_rundef.rename(columns={c: c+'_rundef' for c in def_rundef.columns if c not in ['unique_team_id']})\n",
    "\n",
    "def_stats.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute special teams weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_bio.columns = [str(col) + '_st' for col in st_bio.columns]\n",
    "# st_kickers_roll = pd.merge(st_kickers_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_kickers_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def kicks_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_kickers_roll['kicks'] = st_kickers_roll['kicking_pat_attempts']+st_kickers_roll['kicking_total_attempts']\n",
    "st_kickers_roll ['kicks'] = st_kickers_roll .apply(lambda df: snap_fixs(df, var='kicks'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='kicks'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_kickers = st_kickers_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_punters_roll = pd.merge(st_punters_roll, st_bio, left_on='player_team_id', right_on='unique_id_st', how='left')\n",
    "# st_punters_roll.drop_duplicates(subset=['p_id'], keep='first', inplace=True)\n",
    "\n",
    "def punts_fix(nData, var=None):\n",
    "    if nData[var] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return nData[var]\n",
    "\t\t\n",
    "st_punters_roll['punting_attempts'] = st_punters_roll.apply(lambda df: snap_fixs(df, var='punting_attempts'), axis=1)\n",
    "\n",
    "def weighted(nData, snap_Var='punting_attempts'):\n",
    "    data_cols = nData.select_dtypes(include=[np.number])\n",
    "    num_cols = data_cols[data_cols.columns.drop(list(data_cols.filter(regex='player_game_count|player_id|plyr_number|week|year|team_id')))].columns.tolist()\n",
    "    return pd.Series(np.average(nData[num_cols], weights=nData[snap_Var], axis=0), num_cols)\n",
    "\t\n",
    "st_punters = st_punters_roll.groupby('unique_team_id').apply(weighted).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling File and write out to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_vars = spread_comb[spread_comb['schedule_week'] != '1']\n",
    "\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'score_home',\n",
    "'score_away',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "\n",
    "dfs_list = [spread_ids,\n",
    "            tgs_roll,\n",
    "            fo_roll,\n",
    "            qb_stats,\n",
    "            rb_stats,\n",
    "            rec_stats,\n",
    "            ol_stats,\n",
    "           def_stats,\n",
    "           def_rundef,\n",
    "           def_cov,\n",
    "           def_passrush,\n",
    "           st_punters,\n",
    "           st_kickers]\n",
    "\n",
    "dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'],\n",
    "                                            how='left'), dfs_list)\n",
    "\n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "\n",
    "\n",
    "favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "dfs_team = dfs_team.rename(columns={c: c+'_fav' for c in dfs_team.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','home_score','away_score','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "not_fav_df = not_fav_df.rename(columns={c: c+'_dog' for c in not_fav_df.columns if c not in ['unique_team_id','team_id','schedule_week','schedule_season','home_matchup_id','spread_favorite','over_under_line','fav_cover','over_under_result','wl','pf','pa']})\n",
    "\n",
    "not_fav_df.drop(['unique_team_id','wl'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "#not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_matchup_id', 'pf', 'pa', 'overall_performance_tgs_dog',\n",
       "       'offense_tgs_dog', 'pass_tgs_dog', 'pass_blocking_tgs_dog',\n",
       "       'receiving_tgs_dog', 'rushing_tgs_dog', 'run_blocking_tgs_dog',\n",
       "       ...\n",
       "       'kicking_thirty_attempts_dog', 'kicking_thirty_made_dog',\n",
       "       'kicking_thirty_percent_dog', 'kicking_total_attempts_dog',\n",
       "       'kicking_total_made_dog', 'kicking_total_percent_dog',\n",
       "       'kicking_twenty_attempts_dog', 'kicking_twenty_made_dog',\n",
       "       'kicking_twenty_percent_dog', 'kicks_dog'],\n",
       "      dtype='object', length=489)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_fav_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge files and write to modeling_data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDER CONSTRUCTION: Creating function to create modeling file by user selected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "spread_ids = spread_vars[['team_id','home_matchup_id']]\n",
    "spread_ids.columns = ['unique_team_id','home_matchup_id']\n",
    "\n",
    "spread_targs = spread_vars[['team_id',\n",
    "'schedule_week',\n",
    "'schedule_season',\n",
    "'team_favorite_id',\n",
    "'spread_favorite',\n",
    "'over_under_line',\n",
    "'fav_cover',\n",
    "'over_under_result',\n",
    "'fav_homeoraway',\n",
    "'remain_fav',\n",
    "'spread_movement',\n",
    "\"ou_movement\",\n",
    "\"strong_movement\",\n",
    "\"fav_team_stronger\",\n",
    "\"temperature\",\n",
    "\"wind_mph\",\n",
    "\"dome\",\n",
    "\"precip\"]]\n",
    "\n",
    "\n",
    "sample=[spread_vars,tgs_clean,fo_roll,qb_stats,rb_stats,rec_stats,ol_stats,def_stats,def_rundef,def_cov,def_passrush,st_punters,st_kickers]\n",
    "           \n",
    "def fav_ids(nData):\n",
    "    if str(nData['team_favorite_id']) in str(nData['team_id']):\n",
    "        return nData['team_id']\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "def build_model_dataset(data_list=None):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "        data_list: User provides a list of dataframes in format - [df1, df2, df3...] to be used to create modeling dataset.\n",
    "        \n",
    "        Options: \n",
    "        Football Outsiders\n",
    "        fo_roll - \n",
    "        \n",
    "        PFF\n",
    "        -Team Game Summaries -\n",
    "        tgs_roll -\n",
    "\n",
    "        -Passing:\n",
    "        qb_stats -\n",
    "        passing_depth_stats -\n",
    "        passing_pressure_stats -\n",
    "        passing_allowed_pressure_stats -\n",
    "        passing_concept_stats -\n",
    "        time_in_pocket_stats -\n",
    "        \n",
    "        -Receiving:\n",
    "        rec_stats -\n",
    "        receiving_concept -\n",
    "        receiving_depth -\n",
    "        receiving_scheme -\n",
    "        \n",
    "        -Blocking:\n",
    "        ol_stats -\n",
    "        offense_pass_blocking_roll -\n",
    "        offense_run_blocking_roll -\n",
    "        \n",
    "        -Defense:\n",
    "        def_stats -\n",
    "        def_rundef -\n",
    "        def_passrush -\n",
    "        def_cov -\n",
    "        pass_rush_stats -\n",
    "        defense_coverage_summary_stats -\n",
    "        run_defense_stats -\n",
    "        defense_coverage_scheme_stats -\n",
    "        slot_coverage_stats -\n",
    "        \n",
    "        -Special Teams:\n",
    "        st_kickers -\n",
    "        st_punters - \n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_list = [spread_ids]+data_list\n",
    "    dfs_team = reduce(lambda  left,right: pd.merge(left,right,on=['unique_team_id'], how='left'), dataset_list)\n",
    "    spread_targs['fav_team_id'] = spread_targs.apply(lambda nData: fav_ids(nData), axis=1)\n",
    "    favs = spread_targs[~spread_targs['fav_team_id'].isnull()]\n",
    "    not_fav = spread_targs[spread_targs['fav_team_id'].isnull()]\n",
    "\n",
    "    not_fav_df = dfs_team[dfs_team.unique_team_id.isin(not_fav.team_id)]\n",
    "\n",
    "    favs = favs[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    not_fav = not_fav[['team_id','schedule_week','schedule_season','spread_favorite','over_under_line','fav_cover','over_under_result']]\n",
    "    return pd.merge(favs, dfs_team, left_on='team_id', right_on='unique_team_id', how='left').merge(not_fav_df, on='home_matchup_id', how='left')\n",
    "\n",
    "fin_df=build_model_dataset(data_list=sample)\n",
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)\n",
    "#fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df=fin_df.round(2)\n",
    "fin_df.drop_duplicates(subset='home_matchup_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df.to_csv('./modeling_data/nfl_spreads_w'+cur_week_str+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
